{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[pypdf2よりPDFMinerの方が日本語対応及び継続開発中のためよいらしい。](https://self-development.info/%E3%80%90python%E3%80%91pypdf2%E3%81%A7%E3%81%AF%E3%81%AA%E3%81%8Fpdfminer%E3%82%92%E4%BD%BF%E3%81%84%E3%81%BE%E3%81%97%E3%82%87%E3%81%86/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyPDF2\n",
    "https://pythonhosted.org/PyPDF2/  \n",
    "pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#current directoryにあるpdf fileを取得\n",
    "pdffiles=glob(\"*.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Handwritten_Optical_Character_Recognition_OCR_A_Comprehensive_Systematic_Literature_Review_SLR.pdf']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdffiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Handwritten_Optical_Character_Recognition_OCR_A_Comprehensive_Systematic_Literature_Review_SLR.pdf'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf=pdffiles[0]\n",
    "pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReceivedJune24,2020,acceptedJuly16,2020,dateofpublicationJuly28,2020,dateofcurrentversionAugust14,2020.\n",
      "DigitalObjectIdentifier10.1109/ACCESS.2020.3012542\n",
      "HandwrittenOpticalCharacterRecognition\n",
      "(OCR):AComprehensiveSystematic\n",
      "\n",
      "LiteratureReview(SLR)\n",
      "JAMSHEDMEMON\n",
      "1,MAIRASAMI\n",
      "2,RIZWANAHMEDKHAN\n",
      "3,ANDMUEENUDDIN\n",
      "41SchoolofComputing,QuestInternationalUniversityPerak,Ipoh30250,Malaysia\n",
      "2DepartmentofComputerScience,ShaheedZul˝qarAliBhuttoInstituteofScienceandTechnology,Karachi75600,Pakistan\n",
      "3FacultyofIT,BarrettHodgsonUniversity,Karachi74900,Pakistan\n",
      "4DepartmentofSoftwareEngineering,FacultyofScienceandTechnology,IlmaUniversity,Karachi75190,Pakistan\n",
      "Correspondingauthor:MairaSami(maira.sami@szabist.edu.pk)\n",
      "ABSTRACTGiventheubiquityofhandwrittendocumentsinhumantransactions,OpticalCharacter\n",
      "Recognition(OCR)ofdocumentshaveinvaluablepracticalworth.Opticalcharacterrecognitionisascience\n",
      "thatenablestotranslatevarioustypesofdocumentsorimagesintoanalyzable,editableandsearchabledata.\n",
      "Duringlastdecade,researchershaveusedarti˝cialintelligence/machinelearningtoolstoautomatically\n",
      "\n",
      "analyzehandwrittenandprinteddocumentsinordertoconvertthemintoelectronicformat.Theobjectiveof\n",
      "\n",
      "thisreviewpaperistosummarizeresearchthathasbeenconductedoncharacterrecognitionofhandwritten\n",
      "\n",
      "documentsandtoprovideresearchdirections.InthisSystematicLiteratureReview(SLR)wecollected,\n",
      "\n",
      "synthesizedandanalyzedresearcharticlesonthetopicofhandwrittenOCR(andcloselyrelatedtopics)\n",
      "whichwerepublishedbetweenyear2000to2019.Wefollowedwidelyusedelectronicdatabasesby\n",
      "followingpre-de˝nedreviewprotocol.Articlesweresearchedusingkeywords,forwardreferencesearching\n",
      "\n",
      "andbackwardreferencesearchinginordertosearchallthearticlesrelatedtothetopic.Aftercarefully\n",
      "\n",
      "followingstudyselectionprocess176articleswereselectedforthisSLR.Thisreviewarticleservesthe\n",
      "\n",
      "purposeofpresentingstateoftheartresultsandtechniquesonOCRandalsoprovideresearchdirectionsby\n",
      "\n",
      "highlightingresearchgaps.\n",
      "INDEXTERMS\n",
      "Opticalcharacterrecognition,classi˝cation,languages,featureextraction,deeplearning.\n",
      "I.INTRODUCTION\n",
      "PTICALcharacterrecognition(OCR)isasystemthatcon-\n",
      "\n",
      "vertsinputtextintomachine-encodedformat[1].Today,OCR\n",
      "\n",
      "ishelpingnotonlyindigitizingthehandwrittenmedieval\n",
      "\n",
      "manuscripts[2],butalsohelpsinconvertingthetypewritten\n",
      "\n",
      "documentsintodigitalform[3].Thishasmadetheretrieval\n",
      "\n",
      "oftherequiredinformationeasierasonedoesn'thaveto\n",
      "gothroughthepilesofdocumentsand˝lestosearchthe\n",
      "requiredinformation.Organizationsaresatisfyingtheneeds\n",
      "\n",
      "ofdigitalpreservationofhistoricdata[4],lawdocuments[5],\n",
      "\n",
      "educationalpersistence[6]etc.\n",
      "AnOCRsystemdependsmainly,ontheextractionof\n",
      "featuresanddiscrimination/classi˝cationofthesefeatures\n",
      "(basedonpatterns).HandwrittenOCRhavereceivedincreas-\n",
      "ingattentionasasub˝eldofOCR.Itisfurthercategorized\n",
      "\n",
      "intoof˛inesystem[7],[8]andonlinesystem[9]basedon\n",
      "Theassociateeditorcoordinatingthereviewofthismanuscriptand\n",
      "approvingitforpublicationwasJennyMahoney.\n",
      "inputdata.Theof˛inesystemisastaticsysteminwhich\n",
      "\n",
      "inputdataisintheformofscannedimageswhileinonline\n",
      "\n",
      "systemsnatureofinputismoredynamicandisbasedon\n",
      "themovementofpentiphavingcertainvelocity,projection\n",
      "angle,positionandlocuspoint.Therefore,anonlinesystem\n",
      "\n",
      "isconsideredmorecomplexandadvance,asitresolvesthe\n",
      "\n",
      "overlappingproblemofinputdatathatispresentintheof˛ine\n",
      "\n",
      "system.OneoftheearliestOCRsystemswasdevelopedinthe\n",
      "1940s,withtheadvancementinthetechnologyoverthetime,\n",
      "\n",
      "thesystembecamemorerobusttodealwithbothprinted,\n",
      "\n",
      "andhandwrittencharactersandthisledtothecommercial\n",
      "\n",
      "availabilityoftheOCRmachines.In1965,advancereading\n",
      "\n",
      "machine``IBM1287''wasintroducedatthe``worldfair''in\n",
      "\n",
      "NewYork[10].Thiswasthe˝rst-everopticalreader,which\n",
      "wascapableofreadinghandwrittennumbers.Duringthe\n",
      "1970s,researchersfocusedontheimprovementofresponse\n",
      "\n",
      "timeandperformanceoftheOCRsystem.\n",
      "142642ThisworkislicensedunderaCreativeCommonsAttribution4.0License.Formoreinformation,seehttps://creativecommons.org/licenses/by/4.0/\n",
      "VOLUME8,2020\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(pdf, \"rb\") as f:\n",
    "    reader = PyPDF2.PdfFileReader(f)\n",
    "    page = reader.getPage(0)\n",
    "    text = page.extractText()\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "単語が繋がってしまっている。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pdfminer\n",
    "https://github.com/pdfminer/pdfminer.six  \n",
    "pip install pdfminer.six"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 全ページ出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.high_level import extract_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = extract_text(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received June 24, 2020, accepted July 16, 2020, date of publication July 28, 2020, date of current version August 14, 2020.\n",
      "\n",
      "Digital Object Identifier 10.1109/ACCESS.2020.3012542\n",
      "\n",
      "Handwritten Optical Character Recognition\n",
      "(OCR): A Comprehensive Systematic\n",
      "Literature Review (SLR)\n",
      "\n",
      "JAMSHED MEMON 1, MAIRA SAMI 2, RIZWAN AHMED KHAN 3, AND MUEEN UDDIN 4\n",
      "1School of Computing, Quest International University Perak, Ipoh 30250, Malaysia\n",
      "2Department of Computer Science, Shaheed Zulﬁqar Ali Bhutto Institute of Science and Technology, Karachi 75600, Pakistan\n",
      "3Faculty of IT, Barrett Hodgson University, Karachi 74900, Pakistan\n",
      "4Department of Software Engineering, Faculty of Science and Technology, Ilma University, Karachi 75190, Pakistan\n",
      "\n",
      "Corresponding author: Maira Sami (maira.sami@szabist.edu.pk)\n",
      "\n",
      "ABSTRACT Given the ubiquity of handwritten documents in human transactions, Optical Character\n",
      "Recognition (OCR) of documents have invaluable practical worth. Optical character recognition is a science\n",
      "that enables to translate various types of documents or images into analyzable, editable and searchable data.\n",
      "During last decade, researchers have used artiﬁcial intelligence / machine learning tools to automatically\n",
      "analyze handwritten and printed documents in order to convert them into electronic format. The objective of\n",
      "this review paper is to summarize research that has been conducted on character recognition of handwritten\n",
      "documents and to provide research directions. In this Systematic Literature Review (SLR) we collected,\n",
      "synthesized and analyzed research articles on the topic of handwritten OCR (and closely related topics)\n",
      "which were published between year 2000 to 2019. We followed widely used electronic databases by\n",
      "following pre-deﬁned review protocol. Articles were searched using keywords, forward reference searching\n",
      "and backward reference searching in order to search all the articles related to the topic. After carefully\n",
      "following study selection process 176 articles were selected for this SLR. This review article serves the\n",
      "purpose of presenting state of the art results and techniques on OCR and also provide research directions by\n",
      "highlighting research gaps.\n",
      "\n",
      "INDEX TERMS Optical character recognition, classiﬁcation, languages, feature extraction, deep learning.\n",
      "\n",
      "I. INTRODUCTION\n",
      "PTICAL character recognition (OCR) is a system that con-\n",
      "verts input text into machine-encoded format [1]. Today, OCR\n",
      "is helping not only in digitizing the handwritten medieval\n",
      "manuscripts [2], but also helps in converting the typewritten\n",
      "documents into digital form [3]. This has made the retrieval\n",
      "of the required information easier as one doesn’t have to\n",
      "go through the piles of documents and ﬁles to search the\n",
      "required information. Organizations are satisfying the needs\n",
      "of digital preservation of historic data [4], law documents [5],\n",
      "educational persistence [6] etc.\n",
      "\n",
      "An OCR system depends mainly, on the extraction of\n",
      "features and discrimination/classiﬁcation of these features\n",
      "(based on patterns). Handwritten OCR have received increas-\n",
      "ing attention as a subﬁeld of OCR. It is further categorized\n",
      "into ofﬂine system [7], [8] and online system [9] based on\n",
      "\n",
      "The associate editor coordinating the review of this manuscript and\n",
      "\n",
      "approving it for publication was Jenny Mahoney.\n",
      "\n",
      "input data. The ofﬂine system is a static system in which\n",
      "input data is in the form of scanned images while in online\n",
      "systems nature of input is more dynamic and is based on\n",
      "the movement of pen tip having certain velocity, projection\n",
      "angle, position and locus point. Therefore, an online system\n",
      "is considered more complex and advance, as it resolves the\n",
      "overlapping problem of input data that is present in the ofﬂine\n",
      "system.\n",
      "\n",
      "One of the earliest OCR systems was developed in the\n",
      "1940s, with the advancement in the technology over the time,\n",
      "the system became more robust to deal with both printed,\n",
      "and handwritten characters and this led to the commercial\n",
      "availability of the OCR machines. In 1965, advance reading\n",
      "machine ‘‘IBM 1287’’ was introduced at the ‘‘world fair’’ in\n",
      "New York [10]. This was the ﬁrst-ever optical reader, which\n",
      "was capable of reading handwritten numbers. During the\n",
      "1970s, researchers focused on the improvement of response\n",
      "time and performance of the OCR system.\n",
      "\n",
      "142642\n",
      "\n",
      "This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\n",
      "\n",
      "VOLUME 8, 2020\n",
      "\n",
      "\n",
      "J. Memon et al.: Handwritten OCR: A Comprehensive SLR\n",
      "\n",
      "The next two decades from 1980 till 2000, the software\n",
      "system of OCR was developed and deployed in educational\n",
      "institutes, census OCR [11] and for recognition of stamped\n",
      "characters on metallic bar [12]. In the early 2000s, binariza-\n",
      "tion techniques were introduced to preserve historical doc-\n",
      "uments in digital form and provide researchers with access\n",
      "to these documents [13]–[16]. Some of the challenges of\n",
      "binarization of historical documents were the use of non-\n",
      "standard fonts, printing noise and spacing. In mid of 2000,\n",
      "multiple applications were introduced that were helpful for\n",
      "differently-abled people. These applications helped these\n",
      "people in developing reading and writing skills.\n",
      "\n",
      "In the current decade, researchers have worked on different\n",
      "machine learning approaches which include Support Vector\n",
      "Machine (SVM), Random Forests (RF), k Nearest Neigh-\n",
      "bor (kNN), Decision Tree (DT) [17]–[19], Neural Networks\n",
      "etc. Researchers combined these machine learning tech-\n",
      "niques with image processing techniques to increase the accu-\n",
      "racy of the optical character recognition system. Recently\n",
      "researchers have focused on developing techniques for the\n",
      "digitization of handwritten documents, primarily based on\n",
      "deep learning [20] approach. This paradigm shift has been\n",
      "sparked due to adaption of cluster computing and GPUs and\n",
      "better performance by deep learning architectures [21], which\n",
      "includes Recurrent Neural Networks (RNN), Convolutional\n",
      "Neural Network (CNN), Long Short-Term Memory (LSTM)\n",
      "networks etc.\n",
      "\n",
      "This Systematic Literature Review (SLR) serves not only\n",
      "the purpose of presenting literature in the domain of OCR for\n",
      "different languages but also highlight research directions for\n",
      "a new researcher by highlighting weak areas of current OCR\n",
      "systems that need further investigation.\n",
      "\n",
      "This article is organized as follows. Section II discusses\n",
      "review methodology employed in this article. Review\n",
      "methodology section includes review protocol, inclusion and\n",
      "exclusion criteria, search strategy, selection process, qual-\n",
      "ity assessment criteria and metadata synthesis of selected\n",
      "studies. Statistical data from selected studies are presented\n",
      "in Section III. Section IV presents research question and\n",
      "their motivation. Section V discusses different classiﬁcations\n",
      "methods which are used for handwritten OCR. This section\n",
      "will also elaborate on structural and statistical models for\n",
      "optical character recognition. Section VI presents different\n",
      "databases (for speciﬁc language) which are available for\n",
      "research purpose. Section VII presents research overview\n",
      "of language-speciﬁc research in OCR, while Section VIII\n",
      "highlights research trends. Section IX summarizes ﬁndings\n",
      "and also highlights gaps in research that need the attention of\n",
      "the research community.\n",
      "\n",
      "II. REVIEW METHODS\n",
      "As mentioned above,\n",
      "this Systematic Literature Review\n",
      "(SLR) aims to identify and present literature on OCR by for-\n",
      "mulating research questions and selecting relevant research\n",
      "studies. Thus, in summary, this review aims:\n",
      "\n",
      "1) To summarize existing research work (machine learn-\n",
      "ing techniques and databases) on different languages of\n",
      "handwritten character recognition systems.\n",
      "\n",
      "2) To highlight research weakness in order to eliminate\n",
      "\n",
      "them through additional research.\n",
      "\n",
      "3) To identify new research areas within the domain of\n",
      "\n",
      "OCR.\n",
      "We will\n",
      "\n",
      "strategies\n",
      "\n",
      "follow the\n",
      "\n",
      "by\n",
      "Kitchenham et al. [22]. Following the proposed strategy,\n",
      "in subsequent sub- sections review protocol, inclusion and\n",
      "exclusion criteria, search strategy process, selection process\n",
      "and data extraction and synthesis processes are discussed.\n",
      "\n",
      "proposed\n",
      "\n",
      "A. REVIEW PROTOCOL\n",
      "Following the philosophy, principles and measures of the\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Systematic Literature Review (SLR) [22], this systematic\n",
      "study was initialized with the development of comprehensive\n",
      "review protocol. This protocol identiﬁes review background,\n",
      "search strategy, data extraction, research questions and qual-\n",
      "ity assessment criteria for the selection of study and data\n",
      "analysis.\n",
      "\n",
      "The review protocol is what that creates a distinction\n",
      "between an SLR and traditional literature review or narrative\n",
      "review [22]. It also enhances the consistency of the review\n",
      "and reduces the researchers’ biases. This is due to the fact that\n",
      "researchers have to present a search strategy and the criteria\n",
      "for the inclusion of exclusion of any study in the review.\n",
      "\n",
      "B. INCLUSION AND EXCLUSION CRITERIA\n",
      "Setting up an inclusion and exclusion criteria makes sure\n",
      "that only articles that are relevant to study are included. Our\n",
      "criteria include research studies from journals, conferences,\n",
      "symposiums and workshops on the optical character recogni-\n",
      "tion of English, Urdu, Arabic, Persian, Indian and Chinese\n",
      "languages. In this SLR, we considered studies that were\n",
      "published from January 2000 to December 2019.\n",
      "\n",
      "Our initial search based on the keywords only resulted\n",
      "in 1150 research articles related to handwritten OCRs of\n",
      "different languages (refer Figure 1 for complete overview\n",
      "of the selection process). After a thorough review of the\n",
      "articles, we excluded articles that were not clearly related\n",
      "to a handwritten OCR, but appeared in the search, because\n",
      "of keyword match. Additionally, articles were also excluded\n",
      "based on duplicity, non-availability of full text and if the\n",
      "studies were not related to any of our research questions.\n",
      "\n",
      "C. SEARCH STRATEGY\n",
      "Search strategy comprises of automatic and manual search,\n",
      "as shown in Figure 1. An automatic search helped in identi-\n",
      "fying primary studies and to achieve a broader perspective.\n",
      "Therefore, we extended the review by the inclusion of addi-\n",
      "tional studies. As recommended by Kitchenham et al. [22],\n",
      "the manual search strategy was applied to the references of the\n",
      "studies that are identiﬁed after the application of automatic\n",
      "search.\n",
      "\n",
      "VOLUME 8, 2020\n",
      "\n",
      "142643\n",
      "\n",
      "\n",
      "J. Memon et al.: Handwritten OCR: A Comprehensive SLR\n",
      "\n",
      "FIGURE 1. Complete overview of studies selection process.\n",
      "\n",
      "For automatic search, we used standard databases which\n",
      "contain the most relevant research articles. These databases\n",
      "include IEEE Explore, ISI Web of Knowledge, Scopus—\n",
      "Elsevier and Springer. While there is plenty of literature avail-\n",
      "able in the magazine, working papers, newspapers, books\n",
      "and blogs, we did not choose them for this review article\n",
      "as concepts discussed in these sources are not subjected to\n",
      "review process; thus their quality cannot be reliably veriﬁed.\n",
      "General keywords derived from our research questions and\n",
      "the title of the study were used to search for research articles.\n",
      "Our aim was to identify as many relevant articles as possible\n",
      "from the main set of keywords. All possible permutations\n",
      "of Optical character recognition concepts were tried in the\n",
      "search, such as ‘‘optical character recognition’’, ‘‘pattern\n",
      "recognition and OCR’’, ‘‘pattern matching and OCR’’ etc.\n",
      "\n",
      "Once the primary data were obtained by using search\n",
      "strings, the data analysis phase of the obtained research\n",
      "papers began with the intention of considering their relevance\n",
      "to research questions and inclusion and exclusion criteria of\n",
      "the study. After that, a bibliography management tool, i.e.\n",
      "Mendeley, was used for storing all related research articles\n",
      "to be used for referencing purpose. Mendeley also helped in\n",
      "identifying duplicate studies.\n",
      "\n",
      "A manual search was performed with an automatic search\n",
      "to make sure that we had not missed anything. This\n",
      "was achieved through forward and backwards referencing.\n",
      "Furthermore, for data extraction, all the results were imported\n",
      "into a spreadsheet. Snowballing, which is an iterative pro-\n",
      "cess in which references of references are veriﬁed to iden-\n",
      "tify more relevant literature, was applied to primary studies\n",
      "in order to extract more relevant primary studies. Set of\n",
      "primary studies post snowball process was then added to\n",
      "Mendeley.\n",
      "\n",
      "D. STUDY SELECTION PROCESS\n",
      "A tollgate approach was adopted for\n",
      "the selection of\n",
      "study [23]. Therefore, after searching keywords in all rele-\n",
      "vant databases, we extracted 1150 research studies through\n",
      "automatic search. Majority of these 1150 studies, 625 were\n",
      "duplicate studies and were eliminated. Inclusion and exclu-\n",
      "sion criteria based upon title, abstracts, keywords and the\n",
      "type of publication was applied to the remaining 525 studies.\n",
      "This resulted in the exclusion of 268 studies and leaving\n",
      "257 studies. In the next stage, the selection criteria were\n",
      "applied, thus further 102 studies were excluded, and we were\n",
      "left with 155 studies.\n",
      "\n",
      "Once we ﬁnished the automatic search stage, we started a\n",
      "manual search procedure to guarantee the exhaustiveness of\n",
      "the search results. We performed screening of the remaining\n",
      "155 studies and went through the references to check relevant\n",
      "research articles that could have been left search during the\n",
      "automatic search. Manual search added 46 further studies.\n",
      "After adding these studies, pre-ﬁnal list of 201 primary stud-\n",
      "ies was obtained.\n",
      "\n",
      "Next and ﬁnal stage was to apply the quality assessment\n",
      "criteria (QAC) on the pre-ﬁnal list of 201 studies. Quality\n",
      "assessment criteria were applied at the end as this is the\n",
      "ﬁnal step through which a ﬁnal list of studies for SLR was\n",
      "deduced. QAC usually identiﬁes studies whose quality is\n",
      "not helpful in answering the research question. After apply-\n",
      "ing QAC, 25 studies were excluded, and we were left with\n",
      "176 primary studies. Refer Figure 1 for complete step-by-step\n",
      "overview of selection process.\n",
      "\n",
      "Table 1 shows the distribution of the primary / selected\n",
      "studies among various publication sources, before and after\n",
      "applying above mentioned selection process. The same is also\n",
      "shown in Figure 2.\n",
      "\n",
      "142644\n",
      "\n",
      "VOLUME 8, 2020\n",
      "\n",
      "\n",
      "J. Memon et al.: Handwritten OCR: A Comprehensive SLR\n",
      "\n",
      "TABLE 1. Distribution of databases of selected studies before and after\n",
      "applying selection process.\n",
      "\n",
      "176 studies were ﬁnally selected for this review article (refer\n",
      "to Figure 1 for complete overview of the selection process).\n",
      "\n",
      "F. DATA EXTRACTION AND SYNTHESIS\n",
      "During this phase, metadata of selected studies (176) was\n",
      "extracted. As stated earlier, we used Mendeley and MS Excel\n",
      "to manage the metadata of these studies. The main objective\n",
      "of this phase was to record the information that was obtained\n",
      "from the initial studies [22]. The data containing study ID\n",
      "(to identify each study), study title, authors, publication year,\n",
      "publishing platform (conference proceedings, journals, etc.),\n",
      "citation count, and the study context (techniques used in\n",
      "the study) were extracted and recorded in an excel sheet.\n",
      "This data was extracted after a thorough analysis of each\n",
      "study to identify the algorithms and techniques proposed by\n",
      "the researchers. This also helped us to classify the studies\n",
      "according to the languages on which the techniques were\n",
      "applied. Table 2 shows the ﬁelds of the data extracted from\n",
      "research studies.\n",
      "\n",
      "TABLE 2. Extracted meta-data fields of selected studies.\n",
      "\n",
      "FIGURE 2. Distribution of sources / databases of selected studies after\n",
      "applying selection process.\n",
      "\n",
      "E. QUALITY ASSESSMENT CRITERIA\n",
      "Quality Assessment Criteria (QAC) is based on the principle\n",
      "to make a decision related to the overall quality of the selected\n",
      "set of studies [22]. Following criteria were used to assess the\n",
      "quality of selected studies. This criterion helped us to identify\n",
      "the strength of inferences and helped us in selecting the most\n",
      "relevant research studies for our research.\n",
      "Quality Assessment criteria questions:\n",
      "1) Are topics presented in a research paper relevant to the\n",
      "\n",
      "objectives of this review article?\n",
      "\n",
      "2) Does research study describes the context of the\n",
      "\n",
      "research?\n",
      "\n",
      "3) Does research article explains the approach and\n",
      "\n",
      "methodology of research with clarity?\n",
      "\n",
      "4) Is data collection procedure explained If data collection\n",
      "\n",
      "5) Is the process of data analysis explained with proper\n",
      "\n",
      "is done in the study?\n",
      "\n",
      "examples?\n",
      "\n",
      "We evaluated 201 selected studies by using the abovemen-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tioned quality assessment questions in order to determine the\n",
      "credibility of a particular acknowledged study. These ﬁve\n",
      "QA schema is inspired by [23]. The quality of the study was\n",
      "measured depending upon the score of each QA question.\n",
      "Each question was assigned 2 marks, and the study’s quality\n",
      "was considered to be selected if it scored greater than or equal\n",
      "to 5 at the scale of 10. Thus, studies below the score of 5\n",
      "were not included in the research. Following this criterion,\n",
      "\n",
      "III. STATISTICAL RESULTS FROM SELECTED STUDIES\n",
      "In this section, statistical results of the selected studies are\n",
      "presented with respect to their publication sources, citation\n",
      "count status, temporal view, type of languages and type of\n",
      "research methodologies.\n",
      "\n",
      "A. PUBLICATION SOURCES OVERVIEW\n",
      "In this review, most of the included studies are published\n",
      "in reputed journals and leading conferences. Therefore, con-\n",
      "sidering the quality of research studies, we believe that this\n",
      "systematic review can be used as a reference to ﬁnd latest\n",
      "trends and to highlight research directions for further studies\n",
      "in the domain of handwritten OCR. Figure 3 shows the distri-\n",
      "bution of studies derived from different publication sources.\n",
      "Majority of included studies (107) were published in research\n",
      "journals (61%), followed by (61) publications in conference\n",
      "articles (34%). Whereas, few (5) articles were published in\n",
      "workshop proceedings and only (3) relevant articles were\n",
      "found to be presented in symposiums.\n",
      "\n",
      "B. RESEARCH CITATIONS\n",
      "Citation count was obtained from Google Scholar. Overall,\n",
      "selected studies have good citation count, which shows that\n",
      "\n",
      "VOLUME 8, 2020\n",
      "\n",
      "142645\n",
      "\n",
      "\n",
      "J. Memon et al.: Handwritten OCR: A Comprehensive SLR\n",
      "\n",
      "the reference ﬁgure, it can be noticed that there is a variation\n",
      "in the publication count through these years. Statistics show\n",
      "sudden increase in a number of publications in the domain of\n",
      "handwritten character recognition in the years 2002, 2007 and\n",
      "2009. The number of publications remained steady in the\n",
      "remaining years of the 2000s. After 2010 there is again a\n",
      "steady increase in the number publications, i.e. 59 publica-\n",
      "tions in 8 years from 2010-17. During the last two years,\n",
      "we have seen a steep rise in the number of the publication.\n",
      "We found 55 new studies in the last two years as compared\n",
      "59 studies in the previous 8 years. This is conceivably not\n",
      "surprising since the concept of handwritten character recog-\n",
      "nition is catching the interest of more researcher because of\n",
      "the advancement of the research work in the ﬁelds of deep\n",
      "learning and computer vision. We believe that application\n",
      "areas of handwritten OCRs will further increase in the coming\n",
      "years. This is to be noted that these number of studies only\n",
      "include research articles which are related to our research\n",
      "questions.\n",
      "\n",
      "D. LANGUAGE SPECIFIC RESEARCH\n",
      "The distributions/number of selected studies with respect\n",
      "to investigated scripting languages are shown in Figure 6.\n",
      "A total number of selected studies are 176, and out of these\n",
      "172 studies, the English language has the highest contribution\n",
      "of 53 studies in the domain of handwritten character recog-\n",
      "nition, 44 studies related to the Arabic language, 37 studies\n",
      "are on the Indian scripts, 23 on the Chinese language, 118 on\n",
      "the Urdu language, while 14 studies were conducted on the\n",
      "Persian language. Some of the selected articles discussed\n",
      "multiple languages.\n",
      "\n",
      "Figure 7 represents publications count each year with\n",
      "respect\n",
      "to language. Reference ﬁgure shows compiled\n",
      "temporal view of handwritten OCR researches done in\n",
      "different\n",
      "the mentioned era of\n",
      "2000-2019, in this time period there are certain research\n",
      "articles that cover more than one language of handwritten\n",
      "OCR.\n",
      "\n",
      "throughout\n",
      "\n",
      "languages\n",
      "\n",
      "FIGURE 3. Study distribution per publication source.\n",
      "\n",
      "the quality of selected studies is worthy of being added in\n",
      "the review and also implies that researchers are actively\n",
      "working in this area of research. As presented in Figure 4,\n",
      "approximately 95% of the selected studies have at least one\n",
      "citation, except the research articles, which are published\n",
      "recently in 2019. Among selected studies, 33 studies have\n",
      "more than 100 citations, 15 studies have been cited between\n",
      "61-100 times, 25 studies were cited between 33-60 times,\n",
      "16 studies were cited between 16-30 times and 68 studies\n",
      "were cited between 1 and 15 times. Overall, we predict\n",
      "that selected studies citations will increase further because\n",
      "research articles are constantly being published in this\n",
      "domain.\n",
      "\n",
      "Table 3 provides details of research publications with more\n",
      "than 100 citations each. These articles can be considered to\n",
      "have a strong impact on the researchers working to build\n",
      "robust OCR system.\n",
      "\n",
      "C. TEMPORAL VIEW\n",
      "The distribution of number of studies over the period under\n",
      "study (2000 - 2019) can be seen in Figure 5. According to\n",
      "\n",
      "FIGURE 4. Citation count of selected studies. Numeric value within bar shows number of studies that have been cited\n",
      "x times (corresponding values on the x-axis).\n",
      "\n",
      "142646\n",
      "\n",
      "VOLUME 8, 2020\n",
      "\n",
      "\n",
      "J. Memon et al.: Handwritten OCR: A Comprehensive SLR\n",
      "\n",
      ".\n",
      "s\n",
      "n\n",
      "o\n",
      "i\n",
      "t\n",
      "a\n",
      "t\n",
      "i\n",
      "c\n",
      "\n",
      "0\n",
      "0\n",
      "1\n",
      "n\n",
      "a\n",
      "h\n",
      "t\n",
      "\n",
      "e\n",
      "r\n",
      "o\n",
      "m\n",
      "h\n",
      "t\n",
      "i\n",
      "\n",
      "w\n",
      "s\n",
      "n\n",
      "o\n",
      "i\n",
      "t\n",
      "a\n",
      "c\n",
      "i\n",
      "l\n",
      "\n",
      "b\n",
      "u\n",
      "p\n",
      "h\n",
      "c\n",
      "r\n",
      "a\n",
      "e\n",
      "s\n",
      "e\n",
      "R\n",
      "\n",
      ".\n",
      "\n",
      "3\n",
      "\n",
      "E\n",
      "L\n",
      "B\n",
      "A\n",
      "T\n",
      "\n",
      "VOLUME 8, 2020\n",
      "\n",
      "142647\n",
      "\n",
      "\n",
      "FIGURE 5. Publications over the years. On the y -axis is the number of\n",
      "publications.\n",
      "\n",
      "FIGURE 6. Number of selected studies with respect to investigated\n",
      "language. Numeric value within bar shows number of selected studies for\n",
      "the given language.\n",
      "\n",
      "IV. RESEARCH QUESTIONS\n",
      "Research questions play an important role in a systematic lit-\n",
      "erature review because these questions determine the search\n",
      "queries and keywords that will be used to explore research\n",
      "publications. As discussed above, we chose research ques-\n",
      "tions which not only help seasoned researchers but also to\n",
      "researchers entering in the domain of optical character recog-\n",
      "nition to understand where the research in this ﬁeld stands as\n",
      "of today. This review article answers research questions pre-\n",
      "sented in Table 4. Reference table also presents the motivation\n",
      "for each research question.\n",
      "\n",
      "TABLE 4. Research questions and motivation.\n",
      "\n",
      "J. Memon et al.: Handwritten OCR: A Comprehensive SLR\n",
      "\n",
      "V. CLASSIFICATION METHODS OF HANDWRITTEN OCR\n",
      "In handwritten OCR an algorithm is trained on a known\n",
      "dataset, and it discovers how to accurately categorize/classify\n",
      "the alphabets and digits. Classiﬁcation is a process to learn a\n",
      "model on a given input data and map or label it to predeﬁned\n",
      "category or classes [17]. In this section, we have discussed\n",
      "the most prevalent classiﬁcation techniques in OCR research\n",
      "studies beginning from 2000 till 2019.\n",
      "\n",
      "A. ARTIFICIAL NEURAL NETWORKS (ANN)\n",
      "Biological neuron inspired architecture, Artiﬁcial Neural\n",
      "Networks (ANN) consists of numerous processing units\n",
      "called neurons [56]. These processing elements (neurons)\n",
      "work together to model given input data and map it to pre-\n",
      "deﬁned class or label [57]. The main unit in neural networks\n",
      "is nodes (neuron). Weights associated with each node are\n",
      "adjusted to reduce the squared error on training samples\n",
      "in a supervised learning environment (training on labelled\n",
      "samples/data). Figure 8 presents a pictorial representation of\n",
      "Multi-Layer Perceptron (MLP) that consists of three layers,\n",
      "i.e. (input, hidden and output).\n",
      "\n",
      "Feedforward networks / Multi-Layer Perceptron (MLP)\n",
      "achieved renewed interest of research community in the mid\n",
      "1980s as by that time ‘‘Hopﬁeld network’’ provided the way\n",
      "to understand human memory and calculate the state of a\n",
      "neuron [59]. Initially, the computational complexity of ﬁnd-\n",
      "ing weights associated with neurons hindered the application\n",
      "of neural networks. With the advent of deep (many layers)\n",
      "neural architectures, i.e. Recurrent Neural Network (RNN)\n",
      "and Convolutional Neural Networks (CNN), neural networks\n",
      "have established itself as one of the best classiﬁcation tech-\n",
      "nique for recognition tasks including OCR [60]–[63]. Refer\n",
      "Sections VIII and IX-B for current and future research trends.\n",
      "The early implementation of MLP for handwritten OCR\n",
      "was done by Shamsher et al. [64] on the Urdu language. The\n",
      "researchers proposed feed-forward neural network algorithm\n",
      "of MLP (Multi-Layer Perceptrons) [65]. Liu and Suen [66]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used MLP on Farsi and Bangla numerals. One hidden layer\n",
      "was used with the connecting weights estimated by the error\n",
      "backpropagation (BP) algorithm that minimized the squared\n",
      "error criterion. On the other hand, Cirecsan et al. [30] trained\n",
      "ﬁve MLPs with two to nine hidden layers and varying num-\n",
      "bers of hidden units for the recognition of English numerals.\n",
      "Recently, Convolutional Neural Network (CNN) has\n",
      "reported great success in character recognition task [67].\n",
      "A convolutional neural network has been widely used\n",
      "the lan-\n",
      "for classiﬁcation and recognition of almost all\n",
      "guages that have been reviewed for this systematic literature\n",
      "review [68]–[74].\n",
      "\n",
      "B. KERNEL METHODS\n",
      "A number of powerful kernel-based learning models,\n",
      "e.g. Support Vector Machines (SVMs), Kernel Fisher\n",
      "Discriminant Analysis (KFDA) and Kernel Principal Com-\n",
      "ponent Analysis (KPCA) have shown practical relevance for\n",
      "\n",
      "142648\n",
      "\n",
      "VOLUME 8, 2020\n",
      "\n",
      "\n",
      "J. Memon et al.: Handwritten OCR: A Comprehensive SLR\n",
      "\n",
      "FIGURE 7. Selected studies count each year with respect to specific language. y -axis shows the number of selected studies.\n",
      "Specific color within each bar represents specific language as shown in the legend.\n",
      "\n",
      "digit recognition, image classiﬁcation, face detection, object\n",
      "detection, and text classiﬁcation [75]. Kernel Fisher Dis-\n",
      "criminant Analysis (KFDA) and Kernel Principal Component\n",
      "Analysis (KPCA) are also some of the most signiﬁcant kernel\n",
      "methods being used in ofﬂine handwritten character recogni-\n",
      "tion system [76]. A number of researchers still believe that\n",
      "SVM performs better than most of the other techniques in\n",
      "classifying the handwritten characters. This is the reason why\n",
      "SVM is still being used for the purpose of classiﬁcation of\n",
      "characters in HCR [77]–[80].\n",
      "Previously, Boukharouba\n",
      "\n",
      "and\n",
      "Yang et al. [81] used SVM for recognition of Urdu and\n",
      "Arabic handwritten digits. SVMs have also been success-\n",
      "fully implement in image classiﬁcation and affect recogni-\n",
      "tion [82], [83], text classiﬁcation [84] and face and object\n",
      "detection [85], [86].\n",
      "\n",
      "and Bennia\n",
      "\n",
      "[75]\n",
      "\n",
      "C. STATISTICAL METHODS\n",
      "Statistical classiﬁers can be parametric and non-parametric.\n",
      "Parametric classiﬁers have ﬁxed (ﬁnite) number of param-\n",
      "eters, and their complexity is not a function of the size\n",
      "of input data. Parametric classiﬁers are generally fast in\n",
      "learning concept and can even work with the small training\n",
      "set. Example of parametric classiﬁers is Logistic Regression\n",
      "(LR), Linear Discriminant Analysis (LDA), Hidden Markov\n",
      "Model (HMM) etc.\n",
      "\n",
      "On the other hand, non-parametric classiﬁers are more\n",
      "ﬂexible in learning concepts but usually grow in complexity\n",
      "with the size of input data. K Nearest Neighbor (K NN),\n",
      "Decision Trees (DT) are examples of non-parametric tech-\n",
      "niques as their number of parameters grows with the size of\n",
      "the training set.\n",
      "\n",
      "1) NON-PARAMETRIC STATISTICAL METHODS\n",
      "One of the most used and easy to train statistical model for\n",
      "classiﬁcation is k nearest neighbor (kNN) [42], [87], [88].\n",
      "\n",
      "FIGURE 8. An architecture of Multilayer Perceptron (MLP) [58].\n",
      "\n",
      "classiﬁcation problems. For instance, in the context of optical\n",
      "pat- tern, text categorization, time-series prediction, these\n",
      "models have signiﬁcant relevance.\n",
      "\n",
      "In support vector machine, kernel performs mapping of\n",
      "feature vectors into a higher dimensional feature space in\n",
      "order to ﬁnd a hyperplane, which is linearly separates classes\n",
      "by as much margin as possible. Given a training set of labeled\n",
      "examples {(xi, yi), i = 1 . . . l } where xi ∈ (cid:60)n and yi ∈\n",
      "{−1, 1}, a new test example x is classiﬁed by the following\n",
      "function:\n",
      "\n",
      "f (x) = sgn(\n",
      "\n",
      "αiyiK (xi, x) + b)\n",
      "\n",
      "(1)\n",
      "\n",
      "1\n",
      "(cid:88)\n",
      "\n",
      "i=1\n",
      "\n",
      "where:\n",
      "\n",
      "1) K (.,.) is a kernel function\n",
      "2) b is the threshold parameter of the hyperplane\n",
      "3) αi are Lagrange multipliers of a dual optimization prob-\n",
      "\n",
      "lem that describe the separating hyperplane\n",
      "\n",
      "Before the popularization of deep learning methodology,\n",
      "SVM was one of the most robust technique for handwritten\n",
      "\n",
      "VOLUME 8, 2020\n",
      "\n",
      "142649\n",
      "\n",
      "\n",
      "J. Memon et al.: Handwritten OCR: A Comprehensive SLR\n",
      "\n",
      "It is a non-parametric statistical method, which is widely used\n",
      "in optical character recognition. Non-parametric recognition\n",
      "does not involve a-priori information about the data.\n",
      "\n",
      "kNN ﬁnds a number of training samples closest to a new\n",
      "example-based on target function. Based on the value of the\n",
      "targeted function, it infers the value of the output class. The\n",
      "probability of an unknown sample q belonging to class y can\n",
      "be calculated as follows:\n",
      "\n",
      "metrics are used, most common ones are Euclidean distance,\n",
      "city block distance, cross-correlation, normalized correlation\n",
      "etc.\n",
      "\n",
      "In template matching, either template matching technique\n",
      "employs a rigid shape matching algorithm or deformable\n",
      "shape matching algorithm. Thus, creating a different family\n",
      "of template matching. Taxonomy of template matching tech-\n",
      "niques is presented in Figure 9.\n",
      "\n",
      "p(y|q) =\n",
      "\n",
      "(cid:80)\n",
      "\n",
      "k∈K Wk .1(ky=y)\n",
      "(cid:80)\n",
      "k∈K Wk\n",
      "\n",
      "Wk =\n",
      "\n",
      "1\n",
      "d(k, q)\n",
      "\n",
      "(2)\n",
      "\n",
      "(3)\n",
      "\n",
      "where;\n",
      "\n",
      "1) K is the set of nearest neighbors\n",
      "2) ky the class of k\n",
      "3) d(k, q) the Euclidean distance of k from q, respectively.\n",
      "Researchers have been found to use kNN for over a decade\n",
      "now, and they believe that this algorithm achieves relatively\n",
      "good performance for character recognition in their experi-\n",
      "ments performed on different datasets [2], [18], [62], [88].\n",
      "\n",
      "kNN classiﬁes object / ROI based on the majority vote of\n",
      "its neighbours (class) as it assigns class most prevalent among\n",
      "its k nearest neighbours. If k = 1, then the object is simply\n",
      "assigned to a class of that single nearest neighbour [57].\n",
      "\n",
      "2) PARAMETRIC STATISTICAL METHODS\n",
      "As mentioned above, parametric techniques models concepts\n",
      "using ﬁxed (ﬁnite) number of parameters as they assume\n",
      "sample population/training data can be modelled by a proba-\n",
      "bility distribution that has a ﬁxed set of parameters. In OCR\n",
      "research studies, generally, characters are classiﬁed accord-\n",
      "ing to some decision rules such as a maximum likelihood or\n",
      "Bayes method once parameters of the model are learned [36].\n",
      "Hidden Markov Model (HMM) was one of the most fre-\n",
      "\n",
      "quently used parametric statistical method earlier in 2000.\n",
      "\n",
      "HMM, models system/data that is assumed to be a Markov\n",
      "process with hidden states, wherein Markov process prob-\n",
      "ability of one states only depends on previous state [36].\n",
      "It was ﬁrst used in speech recognition during the 1990s\n",
      "before researchers started using it in recognition of optical\n",
      "characters [89]–[91]. It is believed that HMM provides better\n",
      "results even when the availability of lexicons is limited [41].\n",
      "\n",
      "D. TEMPLATE MATCHING TECHNIQUES\n",
      "As the names suggest, template matching is an approach in\n",
      "which images (a small part of an image) is matched with a\n",
      "certain predeﬁned template. Usually, template matching tech-\n",
      "niques employ a sliding window approach in which template\n",
      "image or feature are sliders on the image to determine the sim-\n",
      "ilarity between the two. Based on used similarity (or distance)\n",
      "metric classiﬁcation of different objects are obtained [92].\n",
      "\n",
      "In OCR, template matching technique is used to clas-\n",
      "sify character after matching it with the predeﬁned tem-\n",
      "plate(s) [93]. In literature, different distance (similarity)\n",
      "\n",
      "FIGURE 9. An overview of template matching techniques.\n",
      "\n",
      "One of the most applicable approaches for character recog-\n",
      "nition is deformable template matching (refer Figure 10) as\n",
      "different writers can write character by deforming them in a\n",
      "particular way speciﬁc to writer. In this approach, a deformed\n",
      "image is used to compare it with a database of known images.\n",
      "Thus, matching/classiﬁcation is performed with deformed\n",
      "shapes as a speciﬁc writer could have deformed charac-\n",
      "ter in a particular way [36]. Deformable template matching\n",
      "is further divided into parametric and free form matching.\n",
      "Prototype matching, which is sub-class of parametric\n",
      "deformable matching, matching of done based on a stored\n",
      "prototype (deformed) [94].\n",
      "\n",
      "FIGURE 10.\n",
      "on target image [36].\n",
      "\n",
      "(a) Digit deformations (b) Deformed template superimposed\n",
      "\n",
      "Apart from the deformable template matching approach,\n",
      "second sub-class of template matching is rigid template\n",
      "matching. As the name suggests, rigid template matching\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "does not take into account shape deformations. This approach\n",
      "usually works with features extraction/matching of the image\n",
      "with a template. One of the most common approaches used\n",
      "in OCR to extract shape features is Hough transform, like\n",
      "Arabic [95] and Chinese [96].\n",
      "\n",
      "142650\n",
      "\n",
      "VOLUME 8, 2020\n",
      "\n",
      "\n",
      "J. Memon et al.: Handwritten OCR: A Comprehensive SLR\n",
      "\n",
      "FIGURE 11.\n",
      "\n",
      "(a) Primitive and relations (b) Directed graph for capital letter R and E [100].\n",
      "\n",
      "Second sub-class of rigid template matching is correlation-\n",
      "based matching. In this technique, initially, image similarity\n",
      "is calculated and based on similarity features from speciﬁc\n",
      "regions are extracted and compared [36], [97].\n",
      "\n",
      "E. STRUCTURAL PATTERN RECOGNITION\n",
      "Another classiﬁcation technique that was used by OCR\n",
      "research community before the popularization of kernel\n",
      "methods and neural networks / deep learning approach was\n",
      "structural pattern recognition. Structural pattern recognition\n",
      "aims to classify objects based on a relationship between its\n",
      "pattern structures and usually structures are extracted using\n",
      "pattern primitives (refer Figure 11 for an example of pattern\n",
      "primitives), i.e. edge, contours, connected component geom-\n",
      "etry etc. One of such image primitive that has been used\n",
      "in OCR is Chain Code Histogram (CCH) [98], [99]. CCH\n",
      "effectively describes image / character boundary / curve, thus\n",
      "helping in classify character [57], [75]. Prerequisite condition\n",
      "to apply CCH for OCR is that image should be in binary\n",
      "format, and boundaries should be well deﬁned. Generally, for\n",
      "handwritten character recognition, this condition makes CCH\n",
      "difﬁcult to use. Thus, different research studies and publicly\n",
      "available datasets use/provide binarized images [87].\n",
      "\n",
      "In research studies of OCR, structural models can be\n",
      "further subdivided on the basis of the context of structure,\n",
      "i.e. graphical methods and grammar-based methods. Both of\n",
      "these models are presented in the next two sub-sections.\n",
      "\n",
      "1) GRAPHICAL METHODS\n",
      "A graph (G) is a way to mathematically describe a relation\n",
      "between connected objects and is represented by an ordered\n",
      "pair of nodes (N ) and edges (E). Generally, for OCR, E rep-\n",
      "resents the arc of writing stroke connecting N . The particular\n",
      "arrangement of N and E deﬁne characters / digits / alphabets.\n",
      "Trees (undirected graph, where the direction of the connec-\n",
      "tion is not deﬁned), directed graphs (where the direction of\n",
      "edge to a node is well deﬁned) are used in different research\n",
      "studies to represent characters mathematically [101], [102].\n",
      "\n",
      "As mentioned above, writing structural components are\n",
      "extracted using pattern primitives, i.e. edge, contours, con-\n",
      "nected component geometry etc. The relation between these\n",
      "structures can be deﬁned mathematically using graphs (refer\n",
      "Figure 11 for an example showing how letter ‘‘R’’ and ‘‘E’’\n",
      "can be modelled using graph theory). Then considering spe-\n",
      "ciﬁc graph architecture different structures can be classi-\n",
      "ﬁed using graph similarity measure i.e. similarity ﬂooding\n",
      "algorithm [103], SimRank algorithm [104], Graph similarity\n",
      "scoring [105] and vertex similarity method [106]. In one\n",
      "study [107], graph distance is used to segment overlapping\n",
      "and joined characters as well.\n",
      "\n",
      "2) GRAMMAR BASED METHODS\n",
      "In graph theory, syntactic analysis is also used to ﬁnd similar-\n",
      "ities in structural graph primitives using the concept of gram-\n",
      "mar [108]. The beneﬁt of using grammar concepts in ﬁnding\n",
      "the similarity in graphs comes from the fact that this area\n",
      "is well researched and techniques are well developed. There\n",
      "are different types of grammar based on restriction rules,\n",
      "for example, unrestricted grammar, context-free grammar,\n",
      "context-sensitive grammar and regular grammar. Explanation\n",
      "of these grammar and corresponding applied restrictions are\n",
      "out the scope of this survey article.\n",
      "\n",
      "In OCR literature, usually, strings and trees are used\n",
      "to represent models based on grammar. With well-deﬁned\n",
      "grammar, a string is produced that then can be robustly\n",
      "clas- siﬁed to recognize the character. The tree structure can\n",
      "also model hierarchical relations between structural primi-\n",
      "tives [92]. Trees can also be classiﬁed by analyzing grammar\n",
      "that deﬁnes the tree, thus classifying speciﬁc character [109].\n",
      "\n",
      "VI. DATASETS\n",
      "Generally, for evaluating and benchmarking different OCR\n",
      "algorithms, standardized databases are needed/used to enable\n",
      "a meaningful comparison [55]. Availability of a dataset\n",
      "containing enough amount of data for training and testing\n",
      "purpose is always a fundamental requirement for a quality\n",
      "\n",
      "VOLUME 8, 2020\n",
      "\n",
      "142651\n",
      "\n",
      "\n",
      "J. Memon et al.: Handwritten OCR: A Comprehensive SLR\n",
      "\n",
      "research [110], [111]. Research in the domain of optical\n",
      "character recognition mainly revolves around six different\n",
      "languages, namely, English, Arabic, Indian, Chinese, Urdu\n",
      "and Persian / Farsi script. Thus, there are publicly available\n",
      "datasets for these languages such as MNIST, CEDAR, CEN-\n",
      "PARMI, PE92, UCOM, HCL2000 etc.\n",
      "\n",
      "Following subsections presents an overview of most used\n",
      "\n",
      "datasets for the above mentioned languages.\n",
      "\n",
      "A. CEDAR\n",
      "This legacy dataset, CEDAR, was developed by the\n",
      "researchers at the University of Buffalo in 2002 and is con-\n",
      "sidered among the ﬁrst few large databases of handwritten\n",
      "characters [40]. In CEDAR, the images were scanned at 300\n",
      "dpi. Example character images from the CEDAR database are\n",
      "shown in Figure 12.\n",
      "\n",
      "FIGURE 13. Sample image from CHARS74K dataset [112].\n",
      "\n",
      "image detection, while [113] used the dataset for recognizing\n",
      "characters in early Indian printed documents. Joe et al. [114]\n",
      "used CNN to recognize ofﬂine handwritten characters written\n",
      "in Kannada script.\n",
      "\n",
      "It is to be noted that Kannada is one of many Indian\n",
      "scripts we have included in this research. There are various\n",
      "datasets for Indian language, depending on the script that has\n",
      "been used. For example, CMATERDB is a dataset for Indian\n",
      "script called Bangla [115], [116] and Kaggle’s Tamil hand-\n",
      "written character dataset is another such dataset for Tamil\n",
      "script [117].\n",
      "\n",
      "C. MNIST\n",
      "The MNIST dataset is considered as one of the most used/\n",
      "cited dataset for handwritten digits [30], [42], [118]–[121].\n",
      "It is the subset of the NIST dataset, and that is why it\n",
      "is called modiﬁed NIST or MNIST. The dataset consists\n",
      "of 60,000 training and 10,000 test images. Samples are nor-\n",
      "malized into 20 × 20 grayscale images with reserved aspect\n",
      "ratio, and the normalized images are of size 28 × 28. The\n",
      "dataset greatly reduces the time required for pre-processing\n",
      "and formatting, because it is already in a normalized form.\n",
      "\n",
      "D. UCOM\n",
      "The UCOM is an Urdu language dataset available for\n",
      "research [122]. The authors claim that this dataset could\n",
      "be used for both character recognition as well as writer\n",
      "identiﬁcation. The dataset consists of 53,248 characters and\n",
      "62,000 words written in nasta’liq (calligraphy) style, scanned\n",
      "at 300 dpi. The dataset was created based on the writing\n",
      "of 100 different writers where each writer wrote 6 pages\n",
      "of A4 size. The dataset evaluation is based on 50 text line\n",
      "images as train dataset and 20 text line images as test dataset\n",
      "\n",
      "FIGURE 12. Sample image from CEDAR dataset [42].\n",
      "\n",
      "B. CHARS74K\n",
      "Chars74k [112] dataset was introduced by researchers at the\n",
      "university of surrey in 2009. The dataset contains 74,000\n",
      "images of English and Kannada (Indian) scripts. The database\n",
      "contains street scenes taken in Bangalore, India. One thou-\n",
      "sand nine hundred twenty-two images of signboards, hoard-\n",
      "ings, advertisements and products in supermarkets were\n",
      "photographed. Segmentation of individual characters was\n",
      "done manually, and results were presented in bounding box\n",
      "segmentation. Bag of visual words technique was used for\n",
      "object categorization, and eventually, 62 different classes\n",
      "were created for English and 657 classes for Kannada.\n",
      "\n",
      "A number of researchers have used CHARS74k dataset for\n",
      "recognition of Kannada script. Naiemi [78] applied histogram\n",
      "of oriented gradients features on CHARS74k dataset for spam\n",
      "\n",
      "142652\n",
      "\n",
      "VOLUME 8, 2020\n",
      "\n",
      "\n",
      "J. Memon et al.: Handwritten OCR: A Comprehensive SLR\n",
      "\n",
      "FIGURE 16. Sample writings from IFN/ENIT dataset [37].\n",
      "\n",
      "11,000 training, 2,000 veriﬁcation and 5,000 samples for\n",
      "testing purpose.\n",
      "\n",
      "Another similar, but larger dataset of Farsi numerals was\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "produced by Khosravi and Kabir [51] in 2007. This dataset\n",
      "contains 102,352 digits extracted from registration forms of\n",
      "high school and undergraduate students. Later in 2009 [126],\n",
      "CENPARMI released another larger, extended version of\n",
      "Farsi dataset. This larger dataset contains 432,357 images of\n",
      "dates, words, isolated letters, isolated digits, numeral strings,\n",
      "special symbols, and documents. Refer Figure 17 for exam-\n",
      "ples images from CENPARMI Farsi language dataset.\n",
      "\n",
      "FIGURE 14. Sample handwritten digits from MNIST dataset [42].\n",
      "\n",
      "with reported error rate between 0.004 -0.006%. Example\n",
      "characters from the dataset are presented in Figure 15.\n",
      "\n",
      "FIGURE 15. Example hand written characters from UCOM dataset [122].\n",
      "\n",
      "the advancement of\n",
      "\n",
      "E. IFN/ENIT\n",
      "The IFN/ENIT [37] is the most popular Arabic database\n",
      "of handwritten text. It was developed in 2002 by the\n",
      "researchers at Technical University Braunschweig, Germany\n",
      "research and development of\n",
      "for\n",
      "Arabic handwriting recognition systems. The dataset contains\n",
      "26459 handwritten images of the names of towns and vil-\n",
      "lages in Tunisia. These images consist of 212,211 characters\n",
      "written by 411 different writers, refer Figure 16. Since its\n",
      "inception, the dataset has been widely used by the researchers\n",
      "for the efﬁcient recognition of Arabic characters [41], [48],\n",
      "[123], [124].\n",
      "\n",
      "F. CENPARMI\n",
      "The CENter for Pattern Recognition and Machine Intelli-\n",
      "gence (CENPARMI) introduced the ﬁrst version of Farsi\n",
      "dataset in 2006 [51], [125]. This dataset contains 18,000\n",
      "samples of Farsi numerals. These numerals are divided into\n",
      "\n",
      "FIGURE 17. CENPARMI dataset example images [51].\n",
      "\n",
      "G. HCL2000\n",
      "The HCL2000 is a handwritten Chinese character database,\n",
      "refer Figure 18 to see sample images. The dataset is publicly\n",
      "available for researchers. The dataset contains 3,755 fre-\n",
      "quently used Chinese characters written by 1,000 different\n",
      "subjects. The database is unique in a way that it contains two\n",
      "sub-datasets, one is handwritten Chinese characters dataset,\n",
      "while the other is corresponding writer’s information dataset.\n",
      "This information is provided so that research can be con-\n",
      "ducted not only based on character recognition, but also on\n",
      "the writer’s background such as age, gender, occupation and\n",
      "education [127].\n",
      "\n",
      "H. IAM\n",
      "The IAM [128] is a handwritten database of English\n",
      "language based on Lancaster-Oslo/Bergen (LOB) corpus.\n",
      "\n",
      "VOLUME 8, 2020\n",
      "\n",
      "142653\n",
      "\n",
      "\n",
      "J. Memon et al.: Handwritten OCR: A Comprehensive SLR\n",
      "\n",
      "FIGURE 18. HCL2000 dataset sample images [127].\n",
      "\n",
      "Data were collected from 400 different writers who pro-\n",
      "duced 1,066 forms of English text containing a vocabulary\n",
      "of 82,227 words. Data consists of full English language\n",
      "sentences. The dataset was also used for writer identiﬁca-\n",
      "tion [48]. Researchers were able to successfully identify\n",
      "writer 98% of the time during experiments on IAM dataset.\n",
      "Writing sample from the IAM dataset are presented in\n",
      "Figure 19.\n",
      "\n",
      "FIGURE 19. Sample Image IAM dataset [128].\n",
      "\n",
      "VII. LANGUAGES\n",
      "As mentioned above, researchers working in the domain of\n",
      "optical character recognition have mainly investigated six dif-\n",
      "ferent languages, which are English, Arabic, Indian, Chinese,\n",
      "Urdu and Persian. This is one of the future work to built OCR\n",
      "systems for other languages as well.\n",
      "\n",
      "According to the United Nations Educational, Scientiﬁc\n",
      "and Cultural Organization (UNESCO) report on ‘‘world’s\n",
      "languages in danger,’’ at least 43% of languages spoken in the\n",
      "world are endangered [129]. These large number of languages\n",
      "need the attention of OCR research community as well to pre-\n",
      "serve this heritage from extinction or at least to build such a\n",
      "system that translates documents from endangered languages\n",
      "to electronic form for reference. Data from UNESCO’s report\n",
      "on ‘‘world’s languages in danger’’ is presented in Figure 20.\n",
      "\n",
      "FIGURE 20. Data from UNESCO’s report on ‘‘world’s languages in\n",
      "danger’’ [129].\n",
      "\n",
      "This section presents state-of-the-art results for six lan-\n",
      "\n",
      "guages which are usually studied by researchers.\n",
      "\n",
      "A. ENGLISH LANGUAGE\n",
      "The English Language is the most widely used language in\n",
      "the world. It is the ofﬁcial language of 53 countries and\n",
      "articulated as a ﬁrst language by around 400 million people.\n",
      "Bilinguals use English as an international language. Charac-\n",
      "ter recognition for the English language has been extensively\n",
      "studied throughout many years. In this systematic literature\n",
      "review, the English language has the highest number of\n",
      "publications, i.e. 45 publications after concluding the study\n",
      "selection process (refer Section II-D and Section III-D). The\n",
      "OCR systems for the English language occupy a signiﬁcant\n",
      "place as a large number of studies have been done in the era\n",
      "of 2000-2018 on the English language.\n",
      "\n",
      "The English language OCR systems have been used suc-\n",
      "cessfully in a wide array of commercial applications. The\n",
      "most cited study for English language handwritten OCR is by\n",
      "Plamondon and Srihari [35] in 2000, which have more than\n",
      "2900 citations, refer Table 3. The objective of the research by\n",
      "Plamondon et al. was to present a broad review of state of the\n",
      "art in the ﬁeld of automatic processing of handwriting. This\n",
      "paper explained the phenomenon of pen-based computers and\n",
      "achieved the goal of automatic processing of electronic ink by\n",
      "mimicking and extending the pen-paper metaphor. To identify\n",
      "the shape of the character, structural and rule-based models\n",
      "like (SOFM) self-organized feature map, (TDNN) time-delay\n",
      "neural network and (HMM) hidden Markov model was used.\n",
      "Another comprehensive overview of character recognition\n",
      "presented in [36] by Arica et al. has more than 500 citations.\n",
      "Arica et al. concluded that characters are natural entities,\n",
      "and it is practically impossible for character recognition to\n",
      "impose a strict mathematical rule on the patterns of char-\n",
      "acters. Neither the structural nor the statistical models can\n",
      "signify a complex pattern alone. The statistical and structural\n",
      "information for many characters pattern can be combined by\n",
      "neural networks (NNs) or harmonic markov models (HMM).\n",
      "\n",
      "142654\n",
      "\n",
      "VOLUME 8, 2020\n",
      "\n",
      "\n",
      "J. Memon et al.: Handwritten OCR: A Comprehensive SLR\n",
      "\n",
      "Connell and Jain [9] demonstrated a template-based sys-\n",
      "tem for online character recognition, which is capable of\n",
      "representing different handwriting styles of a particular char-\n",
      "acter. They used decision trees for efﬁcient classiﬁcation of\n",
      "charac- ters and achieved 86% accuracy.\n",
      "\n",
      "Every language has speciﬁc way of writing and have some\n",
      "diverse features that distinguished it with other language.\n",
      "We believe that to efﬁciently recognize handwritten and\n",
      "machine printed text of the English language, researchers\n",
      "have used almost all of the available feature extraction and\n",
      "classiﬁcation techniques. These feature extraction and clas-\n",
      "siﬁcation techniques include but not limited to HOG [130],\n",
      "bidirectional LSTM [131], directional features [132], multi-\n",
      "layer perceptron (MLP) [119], [133], [134], hidden markov\n",
      "model(HMM) [26], [52], [54], [62], Artiﬁcial neural net-\n",
      "work (ANN)\n",
      "[135]–[137] and support vector machine\n",
      "(SVM) [29], [67].\n",
      "\n",
      "Recently trend is shifting away from using hand-\n",
      "crafted features and moving towards deep neural networks.\n",
      "Convolutional Neural Network (CNN) architecture, a class\n",
      "of deep neural networks, has achieved classiﬁcation results\n",
      "that exceed state-of-the-art results speciﬁcally for visual\n",
      "stimuli/input [138]. LeCun [20] proposed CNN architecture\n",
      "based on multiple stages where each stage is further based on\n",
      "multiple layers. Each stage uses feature maps, which are basi-\n",
      "cally arrays containing pixels. These pixels are fed as input to\n",
      "multiple hidden layers for feature extraction and a connected\n",
      "layer, which detects and classiﬁes object [55]. A recent study\n",
      "by [69] used fully convolutional neural network(FCNN) on\n",
      "IAM and RIMES datasets. Results were promising, and\n",
      "researchers achieved the character error rate(CER) and word\n",
      "error rate(WER) of 4.7%, 8.22%, 2.46%, 5.68% respectively.\n",
      "Jayasundara [139] proposed a novel technique called capsule\n",
      "networks(CapsNet) for the handwritten character recogni-\n",
      "tion with very small datasets. Research claims that these\n",
      "techniques require a very small number of training samples\n",
      "for each class. These samples can be as low as 200. It is\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "also claimed that the proposed technique can produce results\n",
      "similar to state-of-the-art systems, with only 10% of the data.\n",
      "When the proposed technique was applied to small datasets,\n",
      "it achieved the accuracy of 90.46%.\n",
      "\n",
      "B. FARSI/PERSIAN SCRIPT\n",
      "Farsi, also known as the Persian Language, is mainly spoken\n",
      "in Iran and partly in Afghanistan, Iraq, Tajikistan and\n",
      "Uzbekistan by approximately 120 million people. The\n",
      "Persian script is considered to be similar to Arabic, Urdu,\n",
      "Pashto and Dari languages. Its nature is also cursive, so the\n",
      "appearance of the letter changes with respect to positions.\n",
      "The script comprises of 32 characters, and unlike the Arabic\n",
      "language, the writing direction of the Farsi language is mostly\n",
      "but not exclusively from right to left.\n",
      "\n",
      "Mozaffari et al. [140] proposed a novel handwritten char-\n",
      "acter recognition method for isolated alphabets and digits of\n",
      "Farsi and Arabic language by using fractal codes. On the\n",
      "basis of the similarities of the characters, they categorized the\n",
      "\n",
      "32 Farsi alphabets into 8 different classes. A multilayer per-\n",
      "ceptron (MLP) (refer Figure 8 for an overview of MLP) was\n",
      "used as a classiﬁer for this purpose. The classiﬁcation rate for\n",
      "characters and digits were 87.26% and 91.37% respectively.\n",
      "However, in another research [141], researchers achieved\n",
      "a recognition rate of 99.5% by using RBF kernel-based sup-\n",
      "port vector machine. Broumandnia and Shanbehzadeh [142]\n",
      "conducted research on Farsi character recognition and claims\n",
      "to propose the fastest approach of recognizing Farsi character\n",
      "using Fast Zernike wavelet moments and artiﬁcial neural net-\n",
      "works (ANN). This model improves on average recognition\n",
      "speed by 8 times.\n",
      "\n",
      "Liu and Suen [66] presented results of handwritten Bangla\n",
      "and Farsi numeral recognition on binary and grayscale\n",
      "images. The researchers applied various character recogni-\n",
      "tion methods and classiﬁers on the three public datasets such\n",
      "as ISI Bangla numerals, CENPARMI Farsi numerals, and\n",
      "IFHCDB Farsi numerals and claimed to have achieved the\n",
      "highest accuracies on the three datasets, i.e. 99.40%, 99.16%,\n",
      "and 99.73%, respectively.\n",
      "\n",
      "In another research, Boukharouba and Bennia [75] pro-\n",
      "posed SVM based system for efﬁcient recognition of hand-\n",
      "written digits. Two feature extraction techniques, namely,\n",
      "chain code histogram (CCH) [143] and white-black transition\n",
      "information, were discussed. The feature extraction algorithm\n",
      "used in the research did not require digits to be normalized.\n",
      "SVM classiﬁer, along with RBF kernel method, was used for\n",
      "classiﬁcation of handwritten Farsi digits named ‘hoda’. This\n",
      "system maintains high performance with less computational\n",
      "complexity as compared to previous systems as the features\n",
      "used were computationally simple.\n",
      "\n",
      "Researchers have also used Convolutional Neural Network\n",
      "(CNN) in conjunction with other techniques for the recog-\n",
      "nition of characters. These techniques have been applied on\n",
      "different datasets to check the accuracy of techniques [74],\n",
      "[87], [144]–[146].\n",
      "\n",
      "C. URDU LANGUAGE\n",
      "Urdu is curvasive language like Arabic, Farsi and many\n",
      "other [147]. In the Urdu language, a notable early attempt to\n",
      "improve the methods for OCR is by Javed et al. in 2009 [148].\n",
      "Their study focuses on the Nasta’liq (calligraphy) style-\n",
      "speciﬁc pre-processing stage in order to overcome the chal-\n",
      "lenges posed by the Nasta’liq style of Urdu handwriting.\n",
      "The steps proposed include page segmentation into lines and\n",
      "further line segmentation into sub-ligatures, followed by base\n",
      "identiﬁcation and base-mark association. 94% of the ligatures\n",
      "were accurately separated with proper mark association.\n",
      "\n",
      "Later in 2009, the ﬁrst known dataset for Urdu hand-\n",
      "writing recognition was developed at Centre for Pattern\n",
      "Recognition and Machine Intelligence (CENPARMI) [149].\n",
      "Sagheer et al. [149] focused on the methods involving data\n",
      "collection, data extraction and pre-processing. The dataset\n",
      "stores dates, isolated digits, numerical strings, isolated letters,\n",
      "special symbols and 57 words. As an experiment, Support\n",
      "Vector Machine (SVM) using a Radial Base Function/kernel\n",
      "\n",
      "VOLUME 8, 2020\n",
      "\n",
      "142655\n",
      "\n",
      "\n",
      "(RBF) was used for classiﬁcation of isolated Urdu digits. The\n",
      "experiment resulted in a high recognition rate of 98.61%.\n",
      "\n",
      "To facilitate multilingual OCR, Hangarge and Dhandra\n",
      "[118] proposed a texture-based method for handwritten script\n",
      "identiﬁcation of three major scripts: English, Devnagari and\n",
      "Urdu. Data from the documents were segmented into text\n",
      "blocks and / or lines. In order to discriminate the scripts,\n",
      "the proposed algorithm extracts ﬁne textural primitives from\n",
      "the input image based on stroke density and pixel density.\n",
      "For experiments, k-nearest neighbour classiﬁer was used for\n",
      "classiﬁcation of the handwritten scripts. The overall accuracy\n",
      "for tri-script and bi-script classiﬁcation peaked up to 88.6%\n",
      "and 97.5% respectively.\n",
      "\n",
      "A study by Pathan et al. [7] in 2012 proposed an approach\n",
      "based on the invariant moment technique to recognize the\n",
      "handwritten isolated Urdu characters. A dataset comprising\n",
      "of 36800 isolated single and multi-component characters\n",
      "was created. For multi-component letters, primary and sec-\n",
      "ondary components were separated, and invariant moments\n",
      "were calculated for each. The researchers used SVM for\n",
      "classiﬁcation, which resulted in an overall performance rate\n",
      "of 93.59%. Similarly, Raza et al. [150] created an ofﬂine sen-\n",
      "tence database with automatic line segmentation. It comprises\n",
      "of 400 digitised forms by 200 different writers.\n",
      "\n",
      "Obaidullah et al. [151] proposed a handwritten numeral\n",
      "script identiﬁcation (HNSI) framework to identify numeral\n",
      "text written in Bangla, Devanagari, Roman and Urdu. The\n",
      "framework is based on a combination of daubechies wavelet\n",
      "decomposition [152] and spatial domain features. A dataset\n",
      "of 4000 handwritten numeral word image for these scripts\n",
      "was created for this purpose. In terms of average accuracy\n",
      "rate, multi-layer perceptron (MLP) (refer Figure 8 for a pic-\n",
      "torial depiction of MLP) proves to be better than NBTree,\n",
      "PART, Random Forest, SMO and Simple Logistic classiﬁers.\n",
      "In 2018, Asma and Kashif [153] presented a compara-\n",
      "tive analysis of raw images and meta-features from UCOM\n",
      "dataset. CNN (Convolutional Neural Network) and an LSTM\n",
      "(Long short-term memory), which is a recurrent neural\n",
      "network-based architecture were used on Urdu language\n",
      "dataset. Researchers claim that CNN provided accuracy\n",
      "of 97.63% and 94.82% on thickness graph and raw images,\n",
      "respectively. While the accuracy of LSTM was 98.53% and\n",
      "99.33%. Naseer and Zafar [153] and Tayyab et al. [154]\n",
      "proposed an OCR model based on CNN and BDLSTM\n",
      "(Bi-Directional LSTM). This model was applied to a dataset\n",
      "containing Urdu news tickers, and results were compared\n",
      "with google’s vision cloud OCR. Researchers found that their\n",
      "proposed model worked better than google’s cloud vision\n",
      "OCR in 2 of the 4 experiments.\n",
      "\n",
      "In 2019 Ahmed et al. [155] proposed a technique based\n",
      "on one-dimensional BLSTM classiﬁer that used recurrent\n",
      "neural network(RNN),\n",
      "term memory(LSTM)\n",
      "long-short\n",
      "and bidirectional recurrent neural networks(BRNN) for the\n",
      "recognition of handwritten Urdu written in Nasta’liq style.\n",
      "Researchers also presented a new dataset of 500 writ-\n",
      "ers named Urdu-Nasta’liq handwritten dataset (UNHD).\n",
      "\n",
      "J. Memon et al.: Handwritten OCR: A Comprehensive SLR\n",
      "\n",
      "various\n",
      "\n",
      "Researchers claim to have achieved very good accuracy in\n",
      "recognizing the characters. The error rate was 6.04–7.93%\n",
      "during\n",
      "study,\n",
      "experiments. During\n",
      "Rafeeq et al. [156] used a deep neural network with dropout\n",
      "regularization. Ligatures were categorized, and the K-Means\n",
      "algorithm is used to cluster the ligatures. Researchers claim\n",
      "that their proposed technique achieved 94.71% accuracy as\n",
      "compared to neural networks which achieved only 74.31%\n",
      "accuracy.\n",
      "\n",
      "another\n",
      "\n",
      "D. CHINESE LANGUAGE\n",
      "Our research includes 23 research publications on the OCR\n",
      "system of Chinese language after concluding the study selec-\n",
      "tion process (refer Section II-D and Section III-D). One\n",
      "of the Earliest research on the Chinese language was done\n",
      "in 2000 by Fu et al. [157]. The researchers used self-growing\n",
      "probabilistic decision-based neural networks (SPDNNs) to\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "develop a user adaptation module for character recognition\n",
      "and personal adaption. The resulting recognition accuracy\n",
      "peaked up to 90.2% in ten adapting cycles.\n",
      "\n",
      "Later in 2005, a comparative study of applying feature\n",
      "vector-based classiﬁcation methods to character recognition\n",
      "by Liu and Fujisawa [67] found that discriminative classiﬁers\n",
      "such as an artiﬁcial neural network (ANN) and support vector\n",
      "machines (SVM) gave higher classiﬁcation accuracies than\n",
      "statistical classiﬁers when the sample size was large. How-\n",
      "ever, in the study SVM demonstrated better accuracies than\n",
      "neural networks in many experiments.\n",
      "\n",
      "In another study Bai and Huo [45] evaluated the use\n",
      "of 8-directional features to recognize online handwritten\n",
      "Chinese characters. Following a series of processing steps,\n",
      "blurred directional features were extracted at uniformly\n",
      "sampled locations using a derived ﬁlter, which forms a\n",
      "512-dimensional vector of raw features. This, in comparison\n",
      "to an earlier approach of using 4-directional features, resulted\n",
      "in a much better performance.\n",
      "\n",
      "In 2009, Zhang et al. [127] presented HCL2000, a\n",
      "large-scale handwritten Chinese Character database. It stores\n",
      "3,755 frequently used characters along with the information\n",
      "of its 1000 different writers. HCL2000 was evaluated using\n",
      "three different algorithms; Linear Discriminant Analysis\n",
      "(LDA), Locality Preserving Projection (LPP) and Marginal\n",
      "Fisher Analysis (MFA). Prior to the analysis, the Nearest\n",
      "Neighbor classiﬁer assigns input image to a character group.\n",
      "The experimental results show MFA and LPP to be better than\n",
      "LDA.\n",
      "\n",
      "Yin et al. [53] proposed ICDAR 2013 competition which\n",
      "received 27 systems for 5 tasks – classiﬁcation on extracted\n",
      "feature data, online/ofﬂine isolated character recognition and\n",
      "online/ofﬂine handwritten text recognition. Techniques used\n",
      "in the systems were inclusive of LDA, Modiﬁed quadratic\n",
      "discriminant function (MFQD), Compound Mahalanobis\n",
      "Function (CMF), convolutional neural network (CNN) and\n",
      "multilayer perceptron (MLP). It was explored that the meth-\n",
      "ods based on neural networks proved to be better for recog-\n",
      "nizing both isolated character and handwritten text.\n",
      "\n",
      "142656\n",
      "\n",
      "VOLUME 8, 2020\n",
      "\n",
      "\n",
      "J. Memon et al.: Handwritten OCR: A Comprehensive SLR\n",
      "\n",
      "During the study in 2016 on accurate recognition of\n",
      "multilingual scene characters, Tian et al. [130] proposed\n",
      "an extension of Histogram of Oriented Gradient (HOG),\n",
      "Cooccurrence HOG (Co-HOG) and Convolutional Co-HOG\n",
      "(ConvCo-HOG) features. The experimental results show the\n",
      "efﬁciency of the approaches used and higher recognition\n",
      "accuracy of multilingual scene texts.\n",
      "\n",
      "In 2018,\n",
      "\n",
      "researchers on Chinese script used neural\n",
      "networks to recognize CAPTCHA (Completely Automated\n",
      "Public Turing test to tell Computers and Humans Apart)\n",
      "recognition [158], Medical document recognition [159],\n",
      "License plate recognition [160] and text recognition in his-\n",
      "torical documents [161]. Researchers used Convolutional\n",
      "Neural Network(CNN) [158], [161], Convolutional Recur-\n",
      "rent Neural Network(CRNN) [159] and Single Deep Neural\n",
      "Network(SDNN) [160] during these studies.\n",
      "\n",
      "During 2019 [162], [163] used techniques based on recur-\n",
      "rent neural network(RNN) for the recognition of online and\n",
      "ofﬂine handwritten text, respectively. On the other hand,\n",
      "Gan et al. [73] used 1-dimensional CNN for the recogni-\n",
      "tion of online handwritten Chinese characters. 1-dimensional\n",
      "CNN seems to have performed better as recognition accuracy\n",
      "of [73] is 98.1% as compared to [163] where the accuracy\n",
      "of 83% was achieved. Zhu et al. [164] proposed a new neural\n",
      "network structure for Chinese handwritten character recog-\n",
      "nition. Researchers adaptively assigned different weights\n",
      "to category-classiﬁers depending on the quality of data.\n",
      "Maximum accuracy of 93.74% was achieved during the\n",
      "experiments on three different datasets.\n",
      "\n",
      "E. ARABIC SCRIPT\n",
      "Research on handwritten Arabic OCR systems has passed\n",
      "through various stages over the past two decades. Studies\n",
      "in the early 2000s focused mainly on the neural net-\n",
      "work methods for recognition and developed variants of\n",
      "databases [165]. In 2002, Pechwitz et al. [37] developed\n",
      "the ﬁrst IFN/ENIT-database to allow for the training and\n",
      "testing of Arabic OCR systems. This is one of the highly\n",
      "cited databases and has been cited more than 470 times.\n",
      "Another database was developed by Mozaffari et al. [166] an\n",
      "Mozaffari and Soltanizadeh [167] in 2006. It stores grey-scale\n",
      "images of isolated ofﬂine handwritten 17,740 Arabic / Farsi\n",
      "numerals and 52,380 characters. Another notable dataset\n",
      "containing Arabic handwritten text images was introduced\n",
      "by Mezghani et al. [168]. The dataset has an open vocab-\n",
      "ulary written by multiple writers (AHTID/ MW). It can\n",
      "be used for word and sentence recognition, and writer\n",
      "identiﬁcation [169].\n",
      "\n",
      "A survey by Lorigo and Govindaraju [18] provides a\n",
      "comprehensive review of the Arabic handwriting recognition\n",
      "methodologies and databases used until 2006. This includes\n",
      "research studies carried out on IFN/ENIT database. These\n",
      "studies mostly involved artiﬁcial neural networks (ANNs),\n",
      "Hidden Markov Models (HMM), holistic and segmentation-\n",
      "based recognition approaches. The limitations pointed out by\n",
      "\n",
      "the review included restrictive lexicons and restrictions on the\n",
      "text appearance.\n",
      "\n",
      "In 2009, Graves and Schmidhuber [24] introduced a\n",
      "globally trained ofﬂine handwriting recognizer based on\n",
      "multi-directional recurrent neural networks and connectionist\n",
      "temporal classiﬁcation. It takes raw pixel data as input. The\n",
      "system had an overall accuracy of 91.4%, which also won the\n",
      "international Arabic recognition competition.\n",
      "\n",
      "Another notable attempt for Arabic OCR was made by\n",
      "Lutf et al. [170] in 2014, which primarily focused on the\n",
      "speciality of the Arabic writing system. The researcher pro-\n",
      "posed a novel method with minimum computation cost for\n",
      "Arabic font recognition based on diacritics. Flood-ﬁll based\n",
      "and clustering-based algorithms were developed for diacritics\n",
      "segmentation. Further, diacritic validation is done to avoid\n",
      "misclassiﬁcation with isolated letters. Compared to other\n",
      "approaches, this method is the fastest with an average recog-\n",
      "nition rate of 98.73% for 10 most popular Arabic fonts.\n",
      "\n",
      "[171]\n",
      "\n",
      "An Arabic handwriting synthesis system devised by\n",
      "Elarian et al.\n",
      "in 2015 synthesizes words from\n",
      "segmented characters. It uses two concatenation models:\n",
      "ExtendedGlyphs connection and the Synthetic-Extensions\n",
      "connection. The impact of the results from this system shows\n",
      "signiﬁcant improvement in the recognition performance of an\n",
      "HMM-based Arabic text recognizer.\n",
      "\n",
      "Akram et l. [172] discussed an analytical approach to\n",
      "develop a recognition system based on HMM Toolkit (HTK).\n",
      "This approach requires no priori segmentation. Features of\n",
      "local densities and statistics are extracted using a vertical\n",
      "sliding windows technique, where each line image is trans-\n",
      "formed into a series of extracted feature vectors. HTK is used\n",
      "in the training phase, and Viterbi algorithm is used in the\n",
      "recognition phase. The system gave an accuracy of 80.26%\n",
      "for words with ‘‘Arabic-numbers’’ database and 78.95% with\n",
      "IFN / ENIT database.\n",
      "\n",
      "In a study conducted in 2016 by Elleuch et al. [173],\n",
      "convolutional neural network (CNN) based on support vector\n",
      "machine (SVM) is explored for recognizing ofﬂine handwrit-\n",
      "ten Arabic. The model automatically extracts features from\n",
      "raw input and performs classiﬁcation.\n",
      "\n",
      "In 2018, researchers applied the technique of DCNN (deep\n",
      "CNN) for recognizing the ofﬂine and handwritten Arabic\n",
      "characters [174]. An accuracy of 98.86% was achieved when\n",
      "the strategy of DCNN using transfer learning was applied\n",
      "to two datasets. In another similar study [175] an OCR\n",
      "technique based on HOG (Histograms of Oriented Gradient)\n",
      "[176] for feature extraction and SVM for character classiﬁ-\n",
      "cation was used on the handwritten dataset. The dataset con-\n",
      "tained names of Jordanian cities, towns and villages yielded\n",
      "an accuracy of 99%. However, when the researchers used\n",
      "multichannel neural network for segmentation and CNN for\n",
      "recognition of machine-printed characters, the experiments\n",
      "on 18pt font showed an overall accuracy of 94.38%.\n",
      "\n",
      "In 2019, Sahlol et al. [177] applied hybrid machine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning approach on CENPARMI dataset. The technique\n",
      "used the rough neighbourhood sets along with binary whale\n",
      "\n",
      "VOLUME 8, 2020\n",
      "\n",
      "142657\n",
      "\n",
      "\n",
      "optimization algorithm. Researcher claims that the proposed\n",
      "technique consumes less amount of time in recognizing\n",
      "the characters as compared to VGGnet, Resnet, Nasnet,\n",
      "Mobilenet, Inception, and Xception. Alrehali et al. [71] used\n",
      "CNN on various datasets of historical Arabic manuscripts\n",
      "and achieved an accuracy of 74% to 88%. In an interest-\n",
      "ing study Ali and Suresha [79] used classiﬁer fusion tech-\n",
      "nique based on a fusion of features moments invariants(MI),\n",
      "runlength matrix(RLM), statistical properties of intensity his-\n",
      "togram(SFIH) and wavelet decomposition(WD) and clas-\n",
      "siﬁers modiﬁed quadratic discriminate functions(MQDF),\n",
      "support vector machine(SVM) and random forest(RF).\n",
      "Researcher claim that the fusion technique provided accuracy\n",
      "of 97% to 99.8%, which is among the highest in Arabic\n",
      "handwritten character recognition.\n",
      "\n",
      "(Hindi)\n",
      "\n",
      "[138], Bangla [116], Hindi\n",
      "\n",
      "F. INDIAN SCRIPT\n",
      "Indian script is collection of scripts used in the sub-continent\n",
      "namely Devanagari\n",
      "[178],\n",
      "Gurmukhi [63], Kannada [179] etc. One of the earliest\n",
      "research on Devanagari\n",
      "script was proposed\n",
      "in 2000 by Lehal and Bhatt [180]. The research was con-\n",
      "ducted on Devanagari script and English numerals. The\n",
      "researchers used data that was already in an isolated form in\n",
      "order to avoid the segmentation phase. The research is based\n",
      "on statistical and structural algorithms [181]. The results\n",
      "of Devanagari scripts were better than English numerals.\n",
      "Devanagari had a recognition rate of 89% with 4.5 confusion\n",
      "rate, while English numerals had a recognition rate of 78%\n",
      "with confusion rate of 18%.\n",
      "\n",
      "Patil and Subbareddy [182] was the ﬁrst researcher to use\n",
      "neural network approach for the identiﬁcation of Indian doc-\n",
      "uments. The researchers propose a system capable of read-\n",
      "ing English, Hindi and Kannada scripts. A modular neural\n",
      "network was used for script identiﬁcation while a two-stage\n",
      "feature extraction system was developed, ﬁrst to dilate the\n",
      "document image and second to ﬁnd average pixel distribution\n",
      "in the resulting images.\n",
      "\n",
      "Sharma et al. [46] proposed a scheme based on quadratic\n",
      "classiﬁer for the recognition of the Devanagari script. The\n",
      "researchers used 64 directional features based on chain\n",
      "code histogram [143] for feature recognition. The proposed\n",
      "scheme resulted in 98.86% and 80.36% accuracy in recogniz-\n",
      "ing Devanagari characters and numeral, respectively. Fivefold\n",
      "cross-validation was used for the computation of results.\n",
      "\n",
      "Two research studies [50], [183] presented in 2007 were\n",
      "based on the use of fuzzy modelling for character recogni-\n",
      "tion of Indian script. The researchers claim that the use of\n",
      "reinforcement learning on a small database of 3500 Hindi\n",
      "numerals helped achieve a recognition rate of 95%.\n",
      "\n",
      "Another research carried out on Hindi numerals [25] used\n",
      "a relatively large dataset of 22,556 isolated numeral samples\n",
      "of Devanagari and 23,392 samples of Bangla scripts. The\n",
      "researchers used three Multi-layer perceptron classiﬁers to\n",
      "classify the characters. In case of a rejection, a 4th percep-\n",
      "tron was used based on the output of the previous three\n",
      "\n",
      "J. Memon et al.: Handwritten OCR: A Comprehensive SLR\n",
      "\n",
      "perceptrons in a ﬁnal attempt to recognize the input numeral.\n",
      "The proposed scheme provided 99.27% recognition accu-\n",
      "racy vs the fuzzy modelling technique, which provided the\n",
      "accuracy of 95%.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u\n",
      "t\n",
      "S\n",
      "\n",
      ".\n",
      ")\n",
      "9\n",
      "1\n",
      "0\n",
      "2\n",
      "-\n",
      "7\n",
      "1\n",
      "0\n",
      "2\n",
      "(\n",
      "\n",
      "s\n",
      "r\n",
      "a\n",
      "e\n",
      "y\n",
      "\n",
      "e\n",
      "e\n",
      "r\n",
      "h\n",
      "t\n",
      "\n",
      "t\n",
      "s\n",
      "a\n",
      "l\n",
      "\n",
      "o\n",
      "t\n",
      "\n",
      "i\n",
      "\n",
      "g\n",
      "n\n",
      "d\n",
      "n\n",
      "o\n",
      "p\n",
      "s\n",
      "e\n",
      "r\n",
      "r\n",
      "o\n",
      "c\n",
      "\n",
      "a\n",
      "t\n",
      "a\n",
      "D\n",
      "\n",
      "i\n",
      "\n",
      ":\n",
      "s\n",
      "e\n",
      "u\n",
      "q\n",
      "n\n",
      "h\n",
      "c\n",
      "e\n",
      "t\n",
      "n\n",
      "o\n",
      "i\n",
      "t\n",
      "a\n",
      "c\n",
      "i\n",
      "f\n",
      "i\n",
      "s\n",
      "s\n",
      "a\n",
      "l\n",
      "c\n",
      "d\n",
      "n\n",
      "a\n",
      "n\n",
      "o\n",
      "i\n",
      "t\n",
      "c\n",
      "a\n",
      "r\n",
      "t\n",
      "x\n",
      "e\n",
      "\n",
      "e\n",
      "r\n",
      "u\n",
      "t\n",
      "a\n",
      "e\n",
      "f\n",
      "d\n",
      "e\n",
      "s\n",
      "u\n",
      "y\n",
      "l\n",
      "t\n",
      "n\n",
      "e\n",
      "u\n",
      "q\n",
      "e\n",
      "r\n",
      "f\n",
      "\n",
      "f\n",
      "o\n",
      "y\n",
      "r\n",
      "a\n",
      "m\n",
      "m\n",
      "u\n",
      "S\n",
      "\n",
      ")\n",
      ".\n",
      "d\n",
      "e\n",
      "u\n",
      "n\n",
      "i\n",
      "t\n",
      "n\n",
      "o\n",
      "C\n",
      "(\n",
      "\n",
      ".\n",
      "\n",
      "5\n",
      "\n",
      "E\n",
      "L\n",
      "B\n",
      "A\n",
      "T\n",
      "\n",
      ".\n",
      "c\n",
      "t\n",
      "e\n",
      "\n",
      "a\n",
      "d\n",
      "a\n",
      "n\n",
      "n\n",
      "a\n",
      "K\n",
      "\n",
      ",\n",
      "i\n",
      "\n",
      "d\n",
      "n\n",
      "H\n",
      "\n",
      "i\n",
      "\n",
      ",\n",
      "\n",
      "a\n",
      "l\n",
      "g\n",
      "n\n",
      "a\n",
      "B\n",
      "\n",
      ",\n",
      "i\n",
      "r\n",
      "a\n",
      "g\n",
      "a\n",
      "n\n",
      "a\n",
      "v\n",
      "e\n",
      "D\n",
      "o\n",
      "t\n",
      "\n",
      "g\n",
      "n\n",
      "\n",
      "i\n",
      "g\n",
      "n\n",
      "o\n",
      "l\n",
      "e\n",
      "b\n",
      "s\n",
      "t\n",
      "p\n",
      "i\n",
      "r\n",
      "c\n",
      "s\n",
      "n\n",
      "o\n",
      "h\n",
      "c\n",
      "r\n",
      "a\n",
      "e\n",
      "s\n",
      "e\n",
      "r\n",
      "\n",
      "VOLUME 8, 2020\n",
      "\n",
      "142661\n",
      "\n",
      "\n",
      "Modiﬁed Neural Network with the aid of elephant herding\n",
      "optimization [188], VGG (Visual Geometry Group) [117] and\n",
      "SVM classiﬁer with the polynomial and linear kernel [80].\n",
      "\n",
      "VIII. RESEARCH TRENDS\n",
      "Characters written by different individuals create large intr-\n",
      "aclass variability, which makes it difﬁcult for classiﬁers to\n",
      "perform robustly. Lately, the research in the domain of optical\n",
      "character recognition has moved towards a deep learning\n",
      "approach [189], [190] with little emphasis on handcrafted\n",
      "features. Deep learning approach has produced improved\n",
      "classiﬁcation accuracy at the cost of increased computational\n",
      "complexity, especially during the training phase.\n",
      "\n",
      "In this section, we have analyzed hand character recog-\n",
      "nition research trend in the last three years (2017-2019).\n",
      "Our analysis is summarized in Table 5. Table 5 includes\n",
      "script under investigation, techniques or classiﬁcation tech-\n",
      "nique employed for OCR, year of publication and respec-\n",
      "tive reference number. This table gives a holistic view of\n",
      "how researchers working on some of the widely used lan-\n",
      "guages are trying to solve the problem of optical character\n",
      "recognition.\n",
      "\n",
      "that\n",
      "\n",
      "the bulk of\n",
      "\n",
      "Table 5 highlights the fact\n",
      "\n",
      "recent\n",
      "publications have employed a deep learning approach in\n",
      "some form. Especially CNN is being used extensively for\n",
      "the recognition of optical characters. This is partially due\n",
      "to the availability of large datasets. Researchers usually\n",
      "employ a deep learning approach for a language that has large\n",
      "enough dataset for deep learning to learn meaningful model.\n",
      "As stated above, although frameworks based on deep learning\n",
      "methods have obtained improved classiﬁcation accuracy but\n",
      "at the cost of increased computational complexity. There\n",
      "are few recent studies that have utilized classical feature\n",
      "extraction approach in combination of feature selection algo-\n",
      "rithms and have obtained state-of-the-art result, for example,\n",
      "[177], [191], [192].\n",
      "\n",
      "IX. CONCLUSION AND FUTURE WORK\n",
      "A. CONCLUSION\n",
      "\n",
      "1) Optical character recognition has been around for the\n",
      "last eight (8) decades. However, initially, products\n",
      "that recognize optical characters were mostly devel-\n",
      "oped by large technology companies. Development\n",
      "of machine learning and deep learning has enabled\n",
      "individual researchers to develop algorithms and tech-\n",
      "niques, which can recognize handwritten manuscripts\n",
      "with greater accuracy.\n",
      "\n",
      "2) In this literature review, we systematically extracted\n",
      "and analyzed research publications on six widely spo-\n",
      "ken languages. We explored that some techniques\n",
      "perform better on one script than on another, e.g.\n",
      "multilayer perceptron classiﬁer gave better accuracy on\n",
      "Devanagri, and Bangla numerals [25], [140] but gave\n",
      "average results for other languages [119], [133], [134].\n",
      "The difference may have been due to the fact of how\n",
      "\n",
      "J. Memon et al.: Handwritten OCR: A Comprehensive SLR\n",
      "\n",
      "speciﬁc technique models a different style of characters\n",
      "and quality of the dataset.\n",
      "\n",
      "3) Most of the published research studies propose a solu-\n",
      "tion for one language or even a subset of a language.\n",
      "Publicly available datasets also include stimuli that are\n",
      "aligned well with each other and fail to incorporate\n",
      "examples that correspond well with real-life scenarios,\n",
      "i.e. writing styles, distorted strokes, variable character\n",
      "thickness and illumination [213].\n",
      "\n",
      "4) It was also observed that researchers are increasingly\n",
      "using Convolutional Neural Networks(CNN) for the\n",
      "recognition of handwritten and machine-printed char-\n",
      "acters. This is due to the fact that CNN based archi-\n",
      "tectures are well suited for recognition tasks where\n",
      "input is an image. CNN was initially used for object\n",
      "recognition tasks in images, e.g. the ImageNet Large\n",
      "Scale Visual Recognition Challenge (ILSVRC) 216].\n",
      "AlexNet [215], GoogLeNet [216] and ResNet [217] are\n",
      "some of the CNN based architectures widely used for\n",
      "visual recognition tasks.\n",
      "\n",
      "B. FUTURE WORK\n",
      "\n",
      "1) As mentioned in Section VII, research in OCR domain\n",
      "is usually done on some of the most widely spoken\n",
      "languages. This is partially due to non-availability of\n",
      "datasets on other languages. One of the future research\n",
      "direction is to conduct research on languages other\n",
      "than widely spoken languages, i.e. regional languages\n",
      "and endangered languages. This can help preserve the\n",
      "cultural heritage of vulnerable communities and will\n",
      "also create a positive impact on strengthening global\n",
      "synergy.\n",
      "\n",
      "2) Another research problem that needs the attention of\n",
      "research community is to build systems that can rec-\n",
      "ognize on-screen characters and text in different con-\n",
      "ditions in daily life scenarios, e.g. text in captions or\n",
      "news tickers, text on signboards, text on billboards etc.\n",
      "This is the domain of ‘‘recognition / classiﬁcation /\n",
      "text in the wild’’. This is a complex problem to solve\n",
      "as a system for such a scenario needs to deal with\n",
      "background clutters, variable illumination condition,\n",
      "variable camera angles, distorted characters and vari-\n",
      "able writing styles [213].\n",
      "\n",
      "3) To build a robust system for ‘‘text\n",
      "\n",
      "in the wild’’,\n",
      "researchers need to come up with challenging datasets\n",
      "that are comprehensive enough to incorporate all\n",
      "possible variations in characters. One such effort\n",
      "is [218]. In another attempt, the research community\n",
      "has launched ‘‘ICDAR 2019: Robustreading chal-\n",
      "lenge on multilingual scene text detection and recog-\n",
      "nition’’ [219]. Aim of this challenge invites research\n",
      "studies that propose a robust system for multi-lingual\n",
      "text recognition in daily life or ‘‘in the wild’’ scenario.\n",
      "Recently report for this challenge has been published\n",
      "and winner methods for different tasks in the challenge\n",
      "\n",
      "142662\n",
      "\n",
      "VOLUME 8, 2020\n",
      "\n",
      "\n",
      "J. Memon et al.: Handwritten OCR: A Comprehensive SLR\n",
      "\n",
      "are all based on different deep learning architectures,\n",
      "e.g. CNN, RNN or LSTM.\n",
      "\n",
      "4) Characters written by different individuals create large\n",
      "intra-class variability, which makes it difﬁcult for clas-\n",
      "siﬁers to perform robustly. Although with the increas-\n",
      "ing utilization of complex deep learning architectures,\n",
      "obtained classiﬁcation accuracy has improved at the\n",
      "same time computational complexity (especially dur-\n",
      "ing the training phase of classiﬁer) has grown. This\n",
      "creates a hurdle in the development of a real-time,\n",
      "robust system for hand character recognition.\n",
      "\n",
      "5) Published research studies have proposed various\n",
      "systems for OCR but one aspect that needs to improve\n",
      "is the commercialization of research. Commercializa-\n",
      "tion of research will help to build low-cost real-life\n",
      "systems for OCR that can turn lots of invaluable infor-\n",
      "mation into searchable/digital data [220].\n",
      "\n",
      "ACKNOWLEDGMENT\n",
      "(Jamshed Memon, Maira Sami, Rizwan Ahmed Khan, and\n",
      "Mueen Uddin contributed equally to this work.)\n",
      "\n",
      "REFERENCES\n",
      "\n",
      "[1] C. C. Tappert, C. Y. Suen, and T. Wakahara, ‘‘The state of the art in\n",
      "online handwriting recognition,’’ IEEE Trans. Pattern Anal. Mach. Intell.,\n",
      "vol. 12, no. 8, pp. 787–808, Aug. 1990, doi: 10.1109/34.57669.\n",
      "\n",
      "[2] M. Kumar, S. R. Jindal, M. K. Jindal, and G. S. Lehal, ‘‘Improved\n",
      "recognition results of medieval handwritten Gurmukhi manuscripts using\n",
      "boosting and bagging methodologies,’’ Neural Process. Lett., vol. 50,\n",
      "pp. 43–56, Sep. 2018.\n",
      "\n",
      "[3] M. A. Radwan, M. I. Khalil, and H. M. Abbas, ‘‘Neural networks pipeline\n",
      "for ofﬂine machine printed Arabic OCR,’’ Neural Process. Lett., vol. 48,\n",
      "no. 2, pp. 769–787, Oct. 2018.\n",
      "\n",
      "[4] P. Thompson, R. T. Batista-Navarro, G. Kontonatsios, J. Carter, E. Toon,\n",
      "J. McNaught, C. Timmermann, M. Worboys, and S. Ananiadou, ‘‘Text\n",
      "mining the history of medicine,’’ PLoS ONE, vol. 11, no. 1, pp. 1–33,\n",
      "Jan. 2016.\n",
      "\n",
      "[5] K. D. Ashley and W. Bridewell, ‘‘Emerging AI & Law approaches to\n",
      "automating analysis and retrieval of electronically stored information in\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discovery proceedings,’’ Artif. Intell. Law, vol. 18, no. 4, pp. 311–320,\n",
      "Dec. 2010, doi: 10.1007/s10506-010-9098-4.\n",
      "\n",
      "[6] R. Zanibbi and D. Blostein, ‘‘Recognition and retrieval of mathemat-\n",
      "ical expressions,’’ Int. J. Document Anal. Recognit., vol. 15, no. 4,\n",
      "pp. 331–357, Dec. 2012, doi: 10.1007/s10032-011-0174-4.\n",
      "\n",
      "[7] I. K. Pathan, A. A. Ali, and R. J. Ramteke, ‘‘Recognition of ofﬂine\n",
      "handwritten isolated Urdu character,’’ Adv. Comput. Res., vol. 4, no. 1,\n",
      "pp. 117–121, 2012.\n",
      "\n",
      "[8] M. T. Parvez and S. A. Mahmoud, ‘‘Ofﬂine Arabic handwritten text\n",
      "recognition: A survey,’’ ACM Comput. Surv., vol. 45, no. 2, p. 23, 2013.\n",
      "[9] S. D. Connell and A. K. Jain, ‘‘Template-based online character recogni-\n",
      "\n",
      "tion,’’ Pattern Recognit., vol. 34, no. 1, pp. 1–14, Jan. 2001.\n",
      "\n",
      "[10] S. Mori, C. Y. Suen, and K. Yamamoto, ‘‘Historical review of OCR\n",
      "research and development,’’ Proc. IEEE, vol. 80, no. 7, pp. 1029–1058,\n",
      "Jul. 1992.\n",
      "\n",
      "[11] R. A. Wilkinson, J. Geist, S. Janet, P. J. Grother, C. J. Burges, R. Creecy,\n",
      "B. Hammond, J. J. Hull, N. Larsen, T. P. Vogl, ‘‘The ﬁrst census optical\n",
      "character recognition system conference,’’ US Dept. Commerce, Nat.\n",
      "Inst. Standards Technol., Gaithersburg, MD, USA, Tech. Rep. 4912, 1992,\n",
      "vol. 184.\n",
      "\n",
      "[12] Z. M. Kovács-V, ‘‘A novel architecture for high quality hand-printed\n",
      "character recognition,’’ Pattern Recognit., vol. 28, no. 11, pp. 1685–1692,\n",
      "Nov. 1995.\n",
      "\n",
      "[13] C. Wolf, J.-M. Jolion, and F. Chassaing, ‘‘Text localization, enhancement\n",
      "and binarization in multimedia documents,’’ in Proc. Object Recognit.\n",
      "Supported User Interact. Service Robots, vol. 2, 2002, pp. 1037–1040.\n",
      "\n",
      "[14] B. Gatos, I. Pratikakis, and S. J. Perantonis, ‘‘An adaptive binarization\n",
      "technique for low quality historical documents,’’ in Proc. Int. Workshop\n",
      "Document Anal. Syst. Berlin, Germany: Springer, 2004, pp. 102–113.\n",
      "\n",
      "[15] J. He, Q. D. M. Do, A. C. Downton, and J. H. Kim, ‘‘A comparison of\n",
      "binarization methods for historical archive documents,’’ in Proc. 8th Int.\n",
      "Conf. Document Anal. Recognit. (ICDAR), 2005, pp. 538–542.\n",
      "\n",
      "[16] T. Sari, L. Souici, and M. Sellami, ‘‘Off-line handwritten Arabic character\n",
      "segmentation algorithm: ACSA,’’ in Proc. 8th Int. Workshop Frontiers\n",
      "Handwriting Recognit., 2002, pp. 452–457.\n",
      "\n",
      "[17] T. M. Mitchell, Machine Learning, 1st ed. New York, NY, USA:\n",
      "\n",
      "McGraw-Hill, 1997.\n",
      "\n",
      "[18] L. M. Lorigo and V. Govindaraju, ‘‘Ofﬂine Arabic handwriting recogni-\n",
      "tion: A survey,’’ IEEE Trans. Pattern Anal. Mach. Intell., vol. 28, no. 5,\n",
      "pp. 712–724, May 2006.\n",
      "\n",
      "[19] R. A. Khan, A. Meyer, H. Konik, and S. Bouakaz, ‘‘Saliency-based\n",
      "framework for facial expression recognition,’’ Frontiers Comput. Sci.,\n",
      "vol. 13, no. 1, pp. 183–198, Feb. 2019.\n",
      "\n",
      "[20] Y. LeCun, Y. Bengio, and G. Hinton, ‘‘Deep learning,’’ Nature, vol. 521,\n",
      "\n",
      "no. 7553, pp. 436–444, 2015.\n",
      "\n",
      "[21] T. M. Breuel, A. Ul-Hasan, M. A. Al-Azawi, and F. Shafait, ‘‘High-\n",
      "performance OCR for printed English and Fraktur using LSTM net-\n",
      "works,’’ in Proc. 12th Int. Conf. Document Anal. Recognit., Aug. 2013,\n",
      "pp. 683–687.\n",
      "\n",
      "[22] B. Kitchenham, R. Pretorius, D. Budgen, O. P. Brereton, M. Turner,\n",
      "M. Niazi, and S. Linkman, ‘‘Systematic literature reviews in software\n",
      "engineering—A tertiary study,’’ Inf. Softw. Technol., vol. 52, no. 8,\n",
      "pp. 792–805, 2010.\n",
      "\n",
      "[23] S. Nidhra, M. Yanamadala, W. Afzal, and R. Torkar, ‘‘Knowledge transfer\n",
      "challenges and mitigation strategies in global software development—\n",
      "A systematic literature review and industrial validation,’’ Int. J. Inf.\n",
      "Manage., vol. 33, no. 2, pp. 333–355, Apr. 2013.\n",
      "\n",
      "[24] A. Graves and J. Schmidhuber, ‘‘Ofﬂine handwriting recognition with\n",
      "multidimensional recurrent neural networks,’’ in Proc. Adv. Neural Inf.\n",
      "Process. Syst., 2009, pp. 545–552.\n",
      "\n",
      "[25] U. Bhattacharya and B. B. Chaudhuri, ‘‘Handwritten numeral databases\n",
      "of indian scripts and multistage recognition of mixed numerals,’’ IEEE\n",
      "Trans. Pattern Anal. Mach. Intell., vol. 31, no. 3, pp. 444–457, Mar. 2009.\n",
      "[26] A. Graves, M. Liwicki, S. Fernández, R. Bertolami, H. Bunke, and\n",
      "J. Schmidhuber, ‘‘A novel connectionist system for unconstrained hand-\n",
      "writing recognition,’’ IEEE Trans. Pattern Anal. Mach. Intell., vol. 31,\n",
      "no. 5, pp. 855–868, May 2009.\n",
      "\n",
      "[27] T. Plötz and G. A. Fink, ‘‘Markov models for ofﬂine handwriting recog-\n",
      "nition: A survey,’’ Int. J. Document Anal. Recognit., vol. 12, no. 4, p. 269,\n",
      "2009.\n",
      "\n",
      "[28] A. A. Desai, ‘‘Gujarati handwritten numeral optical character reorga-\n",
      "nization through neural network,’’ Pattern Recognit., vol. 43, no. 7,\n",
      "pp. 2582–2589, Jul. 2010.\n",
      "\n",
      "[29] G. Vamvakas, B. Gatos, and S. J. Perantonis, ‘‘Handwritten character\n",
      "recognition through two-stage foreground sub-sampling,’’ Pattern Recog-\n",
      "nit., vol. 43, no. 8, pp. 2807–2816, Aug. 2010.\n",
      "\n",
      "[30] D. C. Cireşan, U. Meier, L. M. Gambardella, and J. Schmidhuber, ‘‘Deep,\n",
      "big, simple neural nets for handwritten digit recognition,’’ Neural Com-\n",
      "put., vol. 22, no. 12, pp. 3207–3220, Dec. 2010.\n",
      "\n",
      "[31] J. Pradeep, E. Srinivasan, and S. Himavathi, ‘‘Diagonal based feature\n",
      "extraction for handwritten character recognition system using neural\n",
      "network,’’ in Proc. 3rd Int. Conf. Electron. Comput. Technol. (ICECT),\n",
      "vol. 4, Apr. 2011, pp. 364–368.\n",
      "\n",
      "[32] D. C. Ciresan, U. Meier, L. M. Gambardella, and J. Schmidhuber,\n",
      "‘‘Convolutional neural network committees for handwritten character\n",
      "classiﬁcation,’’ in Proc. Int. Conf. Document Anal. Recognit., Sep. 2011,\n",
      "pp. 1135–1139.\n",
      "\n",
      "[33] V. Patil and S. Shimpi, ‘‘Handwritten English character recognition using\n",
      "neural network,’’ Elixir Comput. Sci. Eng., vol. 41, pp. 5587–5591, Nov.\n",
      "2011.\n",
      "\n",
      "[34] K. Gregor, I. Danihelka, A. Graves, D. J. Rezende, and D. Wierstra,\n",
      "‘‘DRAW: A recurrent neural network for image generation,’’ 2015,\n",
      "arXiv:1502.04623. [Online]. Available: http://arxiv.org/abs/1502.04623\n",
      "[35] R. Plamondon and S. N. Srihari, ‘‘Online and off-line handwriting\n",
      "recognition: A comprehensive survey,’’ IEEE Trans. Pattern Anal. Mach.\n",
      "Intell., vol. 22, no. 1, pp. 63–84, Jan. 2000.\n",
      "\n",
      "[36] N. Arica and F. T. Yarman-Vural, ‘‘An overview of character recognition\n",
      "focused on off-line handwriting,’’ IEEE Trans. Syst., Man, Cybern. C,\n",
      "Appl. Rev., vol. 31, no. 2, pp. 216–233, May 2001.\n",
      "\n",
      "VOLUME 8, 2020\n",
      "\n",
      "142663\n",
      "\n",
      "\n",
      "[37] M. Pechwitz, S. S. Maddouri, V. Märgner, N. Ellouze, and H. Amiri,\n",
      "‘‘IFN/ENIT-database of handwritten Arabic words,’’ in Proc. CIFED,\n",
      "vol. 2, 2002, pp. 127–136.\n",
      "\n",
      "[38] M. S. Khorsheed, ‘‘Off-line Arabic character recognition—A review,’’\n",
      "\n",
      "Pattern Anal. Appl., vol. 5, no. 1, pp. 31–45, 2002.\n",
      "\n",
      "[39] I.-S. Oh and C. Y. Suen, ‘‘A class-modular feedforward neural network for\n",
      "handwriting recognition,’’ Pattern Recognit., vol. 35, no. 1, pp. 229–244,\n",
      "Jan. 2002.\n",
      "\n",
      "[40] S. N. Srihari, S.-H. Cha, H. Arora, and S. Lee, ‘‘Individuality of hand-\n",
      "\n",
      "writing,’’ J. Forensic Sci., vol. 47, no. 4, pp. 1–17, 2002.\n",
      "\n",
      "[41] M. Pechwitz and V. Maergner, ‘‘HMM based approach for handwritten\n",
      "Arabic word recognition using the IFN/ENIT–database,’’ in Proc. 7th Int.\n",
      "Conf. Document Anal. Recognit., 2003, p. 890.\n",
      "\n",
      "[42] C.-L. Liu, K. Nakashima, H. Sako, and H. Fujisawa, ‘‘Handwritten\n",
      "digit recognition: Benchmarking of state-of-the-art techniques,’’ Pattern\n",
      "Recognit., vol. 36, no. 10, pp. 2271–2285, Oct. 2003.\n",
      "\n",
      "[43] U. Pal and B. B. Chaudhuri, ‘‘Indian script character recognition: A sur-\n",
      "vey,’’ Pattern Recognit., vol. 37, no. 9, pp. 1887–1899, Sep. 2004.\n",
      "[44] C.-L. Liu, S. Jaeger, and M. Nakagawa, ‘‘Online recognition of Chinese\n",
      "characters: The state-of-the-art,’’ IEEE Trans. Pattern Anal. Mach. Intell.,\n",
      "vol. 26, no. 2, pp. 198–213, Feb. 2004.\n",
      "\n",
      "[45] Z.-L. Bai and Q. Huo, ‘‘A study on the use of 8-directional features for\n",
      "online handwritten Chinese character recognition,’’ in Proc. 8th Int. Conf.\n",
      "Document Anal. Recognit. (ICDAR), 2005, pp. 262–266.\n",
      "\n",
      "[46] N. Sharma, U. Pal, F. Kimura, and S. Pal, ‘‘Recognition of off-line\n",
      "handwritten devnagari characters using quadratic classiﬁer,’’ in Com-\n",
      "puter Vision, Graphics and Image Processing. Berlin, Germany: Springer,\n",
      "2006, pp. 805–816.\n",
      "\n",
      "[47] A. Graves, S. Fernández, F. Gomez, and J. Schmidhuber, ‘‘Connectionist\n",
      "temporal classiﬁcation: Labelling unsegmented sequence data with recur-\n",
      "rent neural networks,’’ in Proc. 23rd Int. Conf. Mach. Learn. (ICML),\n",
      "2006, pp. 369–376.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[48] M. Bulacu, L. Schomaker, and A. Brink, ‘‘Text-independent writer identi-\n",
      "ﬁcation and veriﬁcation on ofﬂine Arabic handwriting,’’ in Proc. 9th Int.\n",
      "Conf. Document Anal. Recognit. (ICDAR), Sep. 2007, pp. 769–773.\n",
      "[49] M. Liwicki, A. Graves, S. Fernàndez, H. Bunke, and J. Schmidhuber,\n",
      "‘‘A novel approach to on-line handwriting recognition based on bidi-\n",
      "rectional long short-term memory networks,’’ in Proc. 9th Int. Conf.\n",
      "Document Anal. Recognit. (ICDAR), 2007, pp. 1–5.\n",
      "\n",
      "[50] M. Hanmandlu and O. V. R. Murthy, ‘‘Fuzzy model based recognition of\n",
      "handwritten numerals,’’ Pattern Recognit., vol. 40, no. 6, pp. 1840–1854,\n",
      "Jun. 2007.\n",
      "\n",
      "[51] H. Khosravi and E. Kabir, ‘‘Introducing a very large dataset of handwrit-\n",
      "ten farsi digits and a study on their varieties,’’ Pattern Recognit. Lett.,\n",
      "vol. 28, no. 10, pp. 1133–1141, Jul. 2007.\n",
      "\n",
      "[52] A. Graves, M. Liwicki, H. Bunke, J. Schmidhuber, and S. Fernández,\n",
      "‘‘Unconstrained on-line handwriting recognition with recurrent neural\n",
      "networks,’’ in Proc. Adv. Neural Inf. Process. Syst., 2008, pp. 577–584.\n",
      "\n",
      "[53] F. Yin, Q.-F. Wang, X.-Y. Zhang, and C.-L. Liu, ‘‘ICDAR 2013 Chinese\n",
      "handwriting recognition competition,’’ in Proc. 12th Int. Conf. Document\n",
      "Anal. Recognit. (ICDAR), Aug. 2013, pp. 1464–1470.\n",
      "\n",
      "[54] M. Zimmermann and H. Bunke, ‘‘Automatic segmentation of the IAM\n",
      "off-line database for handwritten English text,’’ in Proc. 16th Int. Conf.\n",
      "Pattern Recognit., vol. 4, 2002, pp. 35–39.\n",
      "\n",
      "[55] R. A. Khan, A. Crenn, A. Meyer, and S. Bouakaz, ‘‘A novel database\n",
      "of children’s spontaneous facial expressions (LIRIS-CSE),’’ Image Vis.\n",
      "Comput., vols. 83–84, pp. 61–69, Mar. 2019.\n",
      "\n",
      "[56] S. Rajasekaran and G. V. Pai, Neural Networks, Fuzzy Systems and\n",
      "Evolutionary Algorithms: Synthesis and Applications. New Delh, India:\n",
      "PHI Learning, 2017.\n",
      "\n",
      "[57] P. Vithlani and C. Kumbharana, ‘‘A study of optical character patterns\n",
      "identiﬁed by the different OCR algorithms,’’ Int. J. Sci. Res. Publications,\n",
      "vol. 5, no. 3, pp. 2250–3153, 2015.\n",
      "\n",
      "[58] H. Sharif and R. A. Khan, ‘‘A novel framework for automatic detection of\n",
      "autism: A study on corpus callosum and intracranial brain volume,’’ 2019,\n",
      "arXiv:1903.11323. [Online]. Available: https://arxiv.org/abs/1903.11323\n",
      "[59] A. K. Jain, J. Mao, and K. M. Mohiuddin, ‘‘Artiﬁcial neural networks:\n",
      "\n",
      "A tutorial,’’ Computer, vol. 29, no. 3, pp. 31–44, Mar. 1996.\n",
      "\n",
      "[60] S. N. Nawaz, M. Sarfraz, A. Zidouri, and W. G. Al-Khatib, ‘‘An approach\n",
      "to ofﬂine Arabic character recognition using neural networks,’’ in Proc.\n",
      "10th IEEE Int. Conf. Electron., Circuits Syst. (ICECS), vol. 3, Dec. 2003,\n",
      "pp. 1328–1331.\n",
      "\n",
      "J. Memon et al.: Handwritten OCR: A Comprehensive SLR\n",
      "\n",
      "[61] S. N. Srihari, X. Yang, and G. R. Ball, ‘‘Ofﬂine Chinese handwriting\n",
      "recognition: An assessment of current technology,’’ Frontiers Comput.\n",
      "Sci. China, vol. 1, no. 2, pp. 137–155, May 2007.\n",
      "\n",
      "[62] J. Pradeep, E. Srinivasan, and S. Himavathi, ‘‘Neural network based\n",
      "recognition system integrating feature extraction and classiﬁcation for\n",
      "english handwritten,’’ Int. J. Eng.-Trans. B, Appl., vol. 25, no. 2, p. 99,\n",
      "2012.\n",
      "\n",
      "[63] P. Singh and S. Budhiraja, ‘‘Feature extraction and classiﬁcation tech-\n",
      "niques in OCR systems for handwritten Gurmukhi script—A survey,’’ Int.\n",
      "J. Eng. Res. Appl., vol. 1, no. 4, pp. 1736–1739, 2011.\n",
      "\n",
      "[64] I. Shamsher, Z. Ahmad, J. K. Orakzai, and A. Adnan, ‘‘OCR for printed\n",
      "Urdu script using feed forward neural network,’’ Proc. World Acad. Sci.,\n",
      "Eng. Technol., vol. 23, pp. 172–175, Aug. 2007.\n",
      "\n",
      "[65] R. Al-Jawﬁ, ‘‘Handwriting Arabic character recognition LeNet using\n",
      "neural network,’’ Int. Arab J. Inf. Technol., vol. 6, no. 3, pp. 304–309,\n",
      "2009.\n",
      "\n",
      "[66] C.-L. Liu and C. Y. Suen, ‘‘A new benchmark on the recognition of\n",
      "handwritten bangla and farsi numeral characters,’’ Pattern Recognit.,\n",
      "vol. 42, no. 12, pp. 3287–3295, Dec. 2009.\n",
      "\n",
      "[67] C.-L. Liu and H. Fujisawa, ‘‘Classiﬁcation and learning for character\n",
      "recognition: Comparison of methods and remaining problems,’’ in Proc.\n",
      "Int. Workshop Neural Netw. Learn. Document Anal. Recognit., 2005,\n",
      "pp. 1–7.\n",
      "\n",
      "[68] H. Zhang and Z. Cheng, ‘‘An advanced pyramid network technology for\n",
      "optical character recognition,’’ J. Phys., Conf. Ser., vol. 1302, Aug. 2019,\n",
      "Art. no. 022042.\n",
      "\n",
      "[69] R. Ptucha, F. P. Such, S. Pillai, F. Brockler, V. Singh, and P. Hutkowski,\n",
      "‘‘Intelligent character recognition using fully convolutional neural net-\n",
      "works,’’ Pattern Recognit., vol. 88, pp. 604–613, Apr. 2019.\n",
      "\n",
      "[70] B. Dessai and A. Patil, ‘‘A deep learning approach for optical character\n",
      "recognition of handwritten Devanagari script,’’ in Proc. 2nd Int. Conf.\n",
      "Intell. Comput., Instrum. Control Technol. (ICICICT), vol. 1, Jul. 2019,\n",
      "pp. 1160–1165.\n",
      "\n",
      "[71] B. Alrehali, N. Alsaedi, H. Alahmadi, and N. Abid, ‘‘Historical Arabic\n",
      "manuscripts text recognition using convolutional neural network,’’ in\n",
      "Proc. 6th Conf. Data Sci. Mach. Learn. Appl. (CDMA), Mar. 2020,\n",
      "pp. 37–42.\n",
      "\n",
      "[72] E. Shaikh, I. Mohiuddin, A. Manzoor, G. Latif, and N. Mohammad,\n",
      "‘‘Automated grading for handwritten answer sheets using convolutional\n",
      "neural networks,’’ in Proc. 2nd Int. Conf. New Trends Comput. Sci.\n",
      "(ICTCS), Oct. 2019, pp. 1–6.\n",
      "\n",
      "[73] J. Gan, W. Wang, and K. Lu, ‘‘A new perspective: Recognizing online\n",
      "handwritten Chinese characters via 1-dimensional CNN,’’ Inf. Sci.,\n",
      "vol. 478, pp. 375–390, Apr. 2019.\n",
      "\n",
      "[74] S. Ghasemi and A. H. Jadidinejad, ‘‘Persian text classiﬁcation via\n",
      "character-level convolutional neural networks,’’ in Proc. 8th Conf. AI\n",
      "Robot., 10th RoboCup Iranopen Int. Symp. (IRANOPEN), Apr. 2018,\n",
      "pp. 1–6.\n",
      "\n",
      "[75] A. Boukharouba and A. Bennia, ‘‘Novel feature extraction technique for\n",
      "the recognition of handwritten digits,’’ Appl. Comput. Informat., vol. 13,\n",
      "no. 1, pp. 19–26, Jan. 2017.\n",
      "\n",
      "[76] R. Verma and J. Ali, ‘‘A-survey of feature extraction and classiﬁcation\n",
      "techniques in OCR systems,’’ Int. J. Comput. Appl. Inf. Technol., vol. 1,\n",
      "no. 3, pp. 1–3, 2012.\n",
      "\n",
      "[77] P. Sahare and S. B. Dhok, ‘‘Robust character segmentation and recogni-\n",
      "tion schemes for multilingual Indian document images,’’ IETE Tech. Rev.,\n",
      "vol. 36, no. 2, pp. 209–222, Mar. 2019.\n",
      "\n",
      "[78] F. Naiemi, V. Ghods, and H. Khalesi, ‘‘An efﬁcient character recognition\n",
      "method using enhanced HOG for spam image detection,’’ Soft Comput.,\n",
      "vol. 23, no. 22, pp. 11759–11774, Nov. 2019.\n",
      "\n",
      "[79] A. A. A. Ali and M. Suresha, ‘‘A novel features and classiﬁers fusion\n",
      "technique for recognition of Arabic handwritten character script,’’ Social\n",
      "Netw. Appl. Sci., vol. 1, no. 10, p. 1286, Oct. 2019.\n",
      "\n",
      "[80] V. A. Naik and A. A. Desai, ‘‘Multi-layer classiﬁcation approach\n",
      "for online handwritten Gujarati character recognition,’’ in Computa-\n",
      "tional Intelligence: Theories, Applications and Future Directions, vol. 2.\n",
      "Singapore: Springer, 2019, pp. 595–606.\n",
      "\n",
      "[81] L. Yang, C. Y. Suen, T. D. Bui, and P. Zhang, ‘‘Discrimination of similar\n",
      "handwritten numerals based on invariant curvature features,’’ Pattern\n",
      "Recognit., vol. 38, no. 7, pp. 947–963, Jul. 2005.\n",
      "\n",
      "[82] J. Yang, K. Yu, Y. Gong, and T. Huang, ‘‘Linear spatial pyramid match-\n",
      "ing using sparse coding for image classiﬁcation,’’ in Proc. IEEE Conf.\n",
      "Comput. Vis. Pattern Recognit., Jun. 2009, vol. 1, no. 2, p. 6.\n",
      "\n",
      "142664\n",
      "\n",
      "VOLUME 8, 2020\n",
      "\n",
      "\n",
      "J. Memon et al.: Handwritten OCR: A Comprehensive SLR\n",
      "\n",
      "[83] R. A. Khan, A. Meyer, H. Konik, and S. Bouakaz, ‘‘Framework\n",
      "for reliable, real-time facial expression recognition for low resolu-\n",
      "tion images,’’ Pattern Recognit. Lett., vol. 34, no. 10, pp. 1159–1168,\n",
      "Jul. 2013.\n",
      "\n",
      "[84] M. Haddoud, A. Mokhtari, T. Lecroq, and S. Abdeddaïm, ‘‘Com-\n",
      "bining supervised term-weighting metrics for SVM text classiﬁcation\n",
      "with extended term representation,’’ Knowl. Inf. Syst., vol. 49, no. 3,\n",
      "pp. 909–931, Dec. 2016.\n",
      "\n",
      "[85] J. Ning, J. Yang, S. Jiang, L. Zhang, and M.-H. Yang, ‘‘Object track-\n",
      "ing via dual\n",
      "linear structured SVM and explicit feature map,’’ in\n",
      "Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), Jun. 2016,\n",
      "pp. 4266–4274.\n",
      "\n",
      "[86] Q.-Q. Tao, S. Zhan, X.-H. Li, and T. Kurihara, ‘‘Robust face detection\n",
      "using local CNN and SVM based on kernel combination,’’ Neurocomput-\n",
      "ing, vol. 211, pp. 98–105, Oct. 2016.\n",
      "\n",
      "[87] Y. Akbari, M. J. Jalili, J. Sadri, K. Nouri, I. Siddiqi, and C. Djeddi,\n",
      "‘‘A novel database for automatic processing of persian handwritten bank\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checks,’’ Pattern Recognit., vol. 74, pp. 253–265, Feb. 2018.\n",
      "\n",
      "[88] A. A. Chandio, M. Pickering, and K. Shaﬁ, ‘‘Character classiﬁcation and\n",
      "recognition for Urdu texts in natural scene images,’’ in Proc. Int. Conf.\n",
      "Comput., Math. Eng. Technol. (iCoMET), Mar. 2018, pp. 1–6.\n",
      "\n",
      "[89] S. Alma’adeed, C. Higgens, and D. Elliman, ‘‘Recognition of off-line\n",
      "handwritten Arabic words using hidden Markov model approach,’’ in\n",
      "Proc. 16th Int. Conf. Pattern Recognit., vol. 3, 2002, pp. 481–484.\n",
      "[90] S. Alma’adeed, C. Higgins, and D. Elliman, ‘‘Off-line recognition\n",
      "of handwritten Arabic words using multiple hidden Markov mod-\n",
      "els,’’ in Research and Development in Intelligent Systems XX. London,\n",
      "U.K.: Springer, 2004, pp. 33–40.\n",
      "\n",
      "[91] M. Cheriet, ‘‘Visual recognition of Arabic handwriting: Challenges and\n",
      "new directions,’’ in Arabic and Chinese Handwriting Recognition. Berlin,\n",
      "Germany: Springer, 2008, pp. 1–21.\n",
      "\n",
      "[92] U. Pal, R. Jayadevan, and N. Sharma, ‘‘Handwriting recognition in indian\n",
      "regional scripts: A survey of ofﬂine techniques,’’ ACM Trans. Asian Lang.\n",
      "Inf. Process., vol. 11, no. 1, pp. 1–35, Mar. 2012.\n",
      "\n",
      "[93] V. L. Sahu and B. Kubde, ‘‘Ofﬂine handwritten character recognition\n",
      "techniques using neural network: A review,’’ Int. J. Sci. Res., vol. 2, no. 1,\n",
      "pp. 87–94, 2013.\n",
      "\n",
      "[94] M. E. Tiwari and M. Shreevastava, ‘‘A novel technique to read small and\n",
      "capital handwritten character,’’ Int. J. Adv. Comput. Res., vol. 2, no. 2,\n",
      "p. 127, 2012.\n",
      "\n",
      "[95] S. Touj, S. Touj, N. B. Amara, N. B. Amara, H. Amiri, and H. Amiri,\n",
      "‘‘Two approaches for Arabic script recognition-based segmentation using\n",
      "the Hough transform,’’ in Proc. 9th Int. Conf. Document Anal. Recognit.\n",
      "(ICDAR ), vol. 2, Sep. 2007, pp. 654–658.\n",
      "\n",
      "[96] M.-J. Li and R.-W. Dai, ‘‘A personal handwritten Chinese character\n",
      "recognition algorithm based on the generalized Hough transform,’’ in\n",
      "Proc. 3rd Int. Conf. Document Anal. Recognit. (ICDAR), Washington,\n",
      "DC, USA, 1995, p. 828.\n",
      "[Online]. Available: http://dl.acm.org/\n",
      "citation.cfm?id= 839278.840308\n",
      "\n",
      "[97] A. Chaudhuri, ‘‘Some experiments on optical character recognition sys-\n",
      "tems for different languages using soft computing techniques,’’ Birla Inst.\n",
      "Technol. Mesra, Patna, India, Tech. Rep., 2010.\n",
      "\n",
      "[98] J. Iivarinen and A. Visa, ‘‘Shape recognition of irregular objects,’’ in\n",
      "Intelligent Robots and Computer Vision XV: Algorithms, Techniques,\n",
      "Active Vision, and Materials Handling. Bellingham, WA, USA: SPIE,\n",
      "1996, pp. 25–32.\n",
      "\n",
      "[99] C.-L. Liu, K. Nakashima, H. Sako, and H. Fujisawa, ‘‘Handwritten digit\n",
      "recognition: Investigation of normalization and feature extraction tech-\n",
      "niques,’’ Pattern Recognit., vol. 37, no. 2, pp. 265–279, Feb. 2004.\n",
      "[100] J. P. M. de Sá, ‘‘Structural pattern recognition,’’ in Pattern Recognition.\n",
      "Berlin, Germany: Springer, 2001, pp. 243–289, doi: 10.1007/978-3-642-\n",
      "56651-6_6.\n",
      "\n",
      "[101] S. Lavirott and L. Pottier, ‘‘Mathematical formula recognition using\n",
      "graph grammar,’’ Proc. SPIE, vol. 3305, pp. 44–52, Apr. 1998, doi:\n",
      "10.1117/12.304644.\n",
      "\n",
      "[102] F. Álvaro, J.-A. Sánchez, and J.-M. Benedí, ‘‘Recognition of on-line\n",
      "handwritten mathematical expressions using 2D stochastic context-free\n",
      "grammars and hidden Markov models,’’ Pattern Recognit. Lett., vol. 35,\n",
      "pp. 58–67, Jan. 2014. [Online]. Available: http://www.sciencedirect.\n",
      "com/science/article/pii/S016786551200308X\n",
      "\n",
      "[103] S. Melnik, H. Garcia-Molina, and E. Rahm, ‘‘Similarity ﬂooding: A ver-\n",
      "satile graph matching algorithm and its application to schema matching,’’\n",
      "in Proc. 18th Int. Conf. Data Eng., 2002, pp. 117–128.\n",
      "\n",
      "[104] G. Jeh and J. Widom, ‘‘SimRank: A measure of structural-context\n",
      "similarity,’’ in Proc. 8th ACM SIGKDD Int. Conf. Knowl. Discov-\n",
      "ery Data Mining (KDD), 2002, pp. 538–543. [Online]. Available:\n",
      "http://doi.acm.org/10.1145/775047.775126\n",
      "\n",
      "[105] L. A. Zager and G. C. Verghese, ‘‘Graph similarity scoring and\n",
      "matching,’’ Appl. Math. Lett., vol. 21, no. 1, pp. 86–94, 2008.\n",
      "http://www.sciencedirect.com/science/article/\n",
      "[Online].\n",
      "pii/S0893965907001012\n",
      "\n",
      "Available:\n",
      "\n",
      "[106] E. Leicht, P. Holme, and M. Newman, ‘‘Vertex similarity in networks,’’\n",
      "Phys. Rev. E, Stat. Phys. Plasmas Fluids Relat. Interdiscip. Top., vol. 73,\n",
      "Feb. 2006, Art. no. 026120.\n",
      "\n",
      "[107] P. Sahare and S. B. Dhok, ‘‘Multilingual character segmentation and\n",
      "recognition schemes for Indian document images,’’ IEEE Access, vol. 6,\n",
      "pp. 10603–10617, 2018.\n",
      "\n",
      "[108] M. Flasiński, ‘‘Graph grammar models in syntactic pattern recogni-\n",
      "tion,’’ in Proc. Int. Conf. Comput. Recognit. Syst., R. Burduk, M.\n",
      "Kurzynski, and M. Wozniak, Eds. Springer, 2019. [Online]. Available:\n",
      "https://link.springer.com/chapter/10.1007/978-3-030-19738-4_1#citeas\n",
      "\n",
      "[109] A. Chaudhuri, K. Mandaviya, P. Badelia, and S. K. Ghosh, ‘‘Optical char-\n",
      "acter recognition systems,’’ in Optical Character Recognition Systems for\n",
      "Different Languages With Soft Computing. Cham, Switzerland: Springer,\n",
      "2017, pp. 9–41.\n",
      "\n",
      "[110] R. Hussain, A. Raza, I. Siddiqi, K. Khurshid, and C. Djeddi, ‘‘A compre-\n",
      "hensive survey of handwritten document benchmarks: Structure, usage\n",
      "and evaluation,’’ EURASIP J. Image Video Process., vol. 2015, no. 1,\n",
      "p. 46, Dec. 2015.\n",
      "\n",
      "[111] R. A. Khan, É. Dinet, and H. Konik, ‘‘Visual attention: Effects of blur,’’\n",
      "\n",
      "in Proc. IEEE Int. Conf. Image Process., Sep. 2011, pp. 3289–3292.\n",
      "\n",
      "[112] T. E. de Campos, B. R. Babu, and M. Varma, ‘‘Character recognition in\n",
      "\n",
      "natural images,’’ in Proc. VISAPP, vol. 7, 2009, pp. 1–8.\n",
      "\n",
      "[113] C. Clausner, A. Antonacopoulos, T. Derrick, and S. Pletschacher,\n",
      "‘‘ICDAR2019 competition on recognition of early Indian printed\n",
      "documents—REID2019,’’ in Proc. Int. Conf. Document Anal. Recognit.\n",
      "(ICDAR), Sep. 2019, pp. 1527–1532.\n",
      "\n",
      "[114] K. G. Joe, M. Savit, and K. Chandrasekaran, ‘‘Ofﬂine character\n",
      "characters,’’\n",
      "in\n",
      "(GCAT), Oct. 2019,\n",
      "\n",
      "recognition on segmented handwritten kannada\n",
      "Proc. Global Conf. Advancement Technol.\n",
      "pp. 1–5.\n",
      "\n",
      "[115] A. Choudhury, H. S. Rana, and T. Bhowmik, ‘‘Handwritten Bengali\n",
      "numeral recognition using HOG based feature extraction algorithm,’’ in\n",
      "Proc. 5th Int. Conf. Signal Process. Integr. Netw. (SPIN), Feb. 2018,\n",
      "pp. 687–690.\n",
      "\n",
      "[116] A. S. A. Rabby, S. Haque, S. Islam, S. Abujar, and S. A. Hossain,\n",
      "‘‘BornoNet: Bangla handwritten characters recognition using convolu-\n",
      "tional neural network,’’ Procedia Comput. Sci., vol. 143, pp. 528–535,\n",
      "Jan. 2018.\n",
      "\n",
      "[117] M. A. Pragathi, K. Priyadarshini, S. Saveetha, A. S. Banu, and\n",
      "K. O. M. Aarif, ‘‘Handwritten tamil character recognition UsingDeep\n",
      "learning,’’ in Proc. Int. Conf. Vis. Towards Emerg. Trends Commun. Netw.\n",
      "(ViTECoN), Mar. 2019, pp. 1–5.\n",
      "\n",
      "[118] M. Hangarge and B. V. Dhandra, ‘‘Ofﬂine handwritten script identiﬁca-\n",
      "tion in document images,’’ Int. J. Comput. Appl., vol. 4, no. 6, pp. 6–10,\n",
      "Jul. 2010.\n",
      "\n",
      "[119] C.-L. Liu, K. Nakashima, H. Sako, and H. Fujisawa, ‘‘Handwritten digit\n",
      "recognition using state-of-the-art techniques,’’ in Proc. 8th Int. Workshop\n",
      "Frontiers Handwriting Recognit., 2002, pp. 320–325.\n",
      "\n",
      "[120] G. Vamvakas, B. Gatos, and S. Perantonis, ‘‘Hierarchical classiﬁcation of\n",
      "handwritten characters based on novel structural features,’’ in Proc. 11th\n",
      "Int. Conf. Frontiers Handwriting Recognition (ICFHR), Montreal, QC,\n",
      "Canada, 2008, pp. 535–539.\n",
      "\n",
      "[121] U. R. Babu, A. K. Chintha, and Y. Venkateswarlu, ‘‘Handwritten digit\n",
      "recognition using structural, statistical features and k-nearest neigh-\n",
      "bor classiﬁer,’’ Int. J. Inf. Eng. Electron. Bus., vol. 6, no. 1, p. 62,\n",
      "2014.\n",
      "\n",
      "[122] S. B. Ahmed, S. Naz, S. Swati, M. I. Razzak, A. I. Umar, and A. A. Khan,\n",
      "‘‘Ucom ofﬂine dataset—An Urdu handwritten dataset generation,’’ Int.\n",
      "Arab J. Inf. Technol., vol. 14, no. 2, pp. 239–245, 2017.\n",
      "\n",
      "[123] H. El Abed and V. Margner, ‘‘The IFN/ENIT-database—A tool to develop\n",
      "Arabic handwriting recognition systems,’’ in Proc. 9th Int. Symp. Signal\n",
      "Process. Appl. (ISSPA), Feb. 2007, pp. 1–4.\n",
      "\n",
      "[124] V. Margner and H. El Abed, ‘‘Arabic handwriting recognition competi-\n",
      "tion,’’ in Proc. 9th Int. Conf. Document Anal. Recognit. (ICDAR), vol. 2,\n",
      "2007, pp. 1274–1278.\n",
      "\n",
      "VOLUME 8, 2020\n",
      "\n",
      "142665\n",
      "\n",
      "\n",
      "[125] F. Solimanpour, J. Sadri, and C. Y. Suen, ‘‘Standard databases for recog-\n",
      "nition of handwritten digits, numerical strings, legal amounts, letters and\n",
      "dates in farsi language,’’ in Proc. 10th Int. Workshop Frontiers Handwrit-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ing Recognit., 2006, pp. 1–6.\n",
      "\n",
      "[126] P. J. Haghighi, N. Nobile, C. L. He, and C. Y. Suen, ‘‘A new large-scale\n",
      "multi-purpose handwritten farsi database,’’ in Proc. Int. Conf. Image Anal.\n",
      "Recognit. Berlin, Germany: Springer, 2009, pp. 278–286.\n",
      "\n",
      "[127] H. Zhang, J. Guo, G. Chen, and C. Li, ‘‘HCL2000—A large-scale hand-\n",
      "written Chinese character database for handwritten character recogni-\n",
      "tion,’’ in Proc. 10th Int. Conf. Document Anal. Recognit. (ICDAR), 2009,\n",
      "pp. 286–290.\n",
      "\n",
      "[128] U.-V. Marti and H. Bunke, ‘‘The IAM-database: An english sentence\n",
      "database for ofﬂine handwriting recognition,’’ Int. J. Document Anal.\n",
      "Recognit., vol. 5, no. 1, pp. 39–46, Nov. 2002.\n",
      "\n",
      "[129] C. Moseley, Ed., Atlas of the World’s Languages in Danger. Paris, France:\n",
      "\n",
      "UNESCO Publishing, 2010.\n",
      "\n",
      "[130] S. Tian, U. Bhattacharya, S. Lu, B. Su, Q. Wang, X. Wei, Y. Lu,\n",
      "and C. L. Tan, ‘‘Multilingual scene character recognition with co-\n",
      "occurrence of histogram of oriented gradients,’’ Pattern Recognit., vol. 51,\n",
      "pp. 125–134, Mar. 2016.\n",
      "\n",
      "[131] A. H. Toselli, E. Vidal, V. Romero, and V. Frinken, ‘‘HMM word graph\n",
      "based keyword spotting in handwritten document images,’’ Inf. Sci.,\n",
      "vols. 370–371, pp. 497–518, Nov. 2016.\n",
      "\n",
      "[132] S. Deshmukh and L. Ragha, ‘‘Analysis of directional features–stroke\n",
      "and contour for handwritten character Recognition,’’ in Proc. IEEE Int.\n",
      "Advance Comput. Conf. (IACC), Mar. 2009, pp. 1114–1118.\n",
      "\n",
      "[133] S. Ahlawat and R. Rishi, ‘‘Off-line handwritten numeral recognition using\n",
      "hybrid feature set—A comparative analysis,’’ Procedia Comput. Sci.,\n",
      "vol. 122, pp. 1092–1099, Jan. 2017.\n",
      "\n",
      "[134] P. Sharma and R. Singh, ‘‘Performance of English character recognition\n",
      "with and without noise,’’ Int. J. Comput. Trends Technol., vol. 4, no. 3,\n",
      "pp. 400–403, 2013.\n",
      "\n",
      "[135] C. I. Patel, R. Patel, and P. Patel, ‘‘Handwritten character recognition\n",
      "using neural network,’’ Int. J. Sci. Eng. Res., vol. 2, no. 5, pp. 1–6, 2011.\n",
      "[136] P. Zhang, T. D. Bui, and C. Y. Suen, ‘‘A novel cascade ensemble classiﬁer\n",
      "system with a high recognition performance on handwritten digits,’’\n",
      "Pattern Recognit., vol. 40, no. 12, pp. 3415–3429, Dec. 2007.\n",
      "\n",
      "[137] S. Saha, N. Paul, S. K. Das, and S. Kundu, ‘‘Optical character recognition\n",
      "using 40-point feature extraction and artiﬁcial neural network,’’ Int. J.\n",
      "Adv. Res. Comput. Sci. Softw. Eng., vol. 3, no. 4, pp. 1–8, 2013.\n",
      "[138] M. Avadesh and N. Goyal, ‘‘Optical character recognition for Sanskrit\n",
      "using convolution neural networks,’’ in Proc. 13th IAPR Int. Workshop\n",
      "Document Anal. Syst. (DAS), Apr. 2018, pp. 447–452.\n",
      "Jayasekara,\n",
      "\n",
      "J. Rajasegaran,\n",
      "S. Seneviratne, and R. Rodrigo, ‘‘TextCaps: Handwritten character\n",
      "recognition with very small datasets,’’ in Proc. IEEE Winter Conf. Appl.\n",
      "Comput. Vis. (WACV), Jan. 2019, pp. 254–262.\n",
      "\n",
      "Jayasundara, S.\n",
      "\n",
      "Jayasekara, H.\n",
      "\n",
      "[139] V.\n",
      "\n",
      "[140] S. Mozaffari, K. Faez, and H. R. Kanan, ‘‘Recognition of isolated hand-\n",
      "written Farsi/Arabic alphanumeric using fractal codes,’’ in Proc. 6th IEEE\n",
      "Southwest Symp. Image Anal. Interpretation, Mar. 2004, pp. 104–108.\n",
      "\n",
      "[141] H. Soltanzadeh and M. Rahmati, ‘‘Recognition of persian handwritten\n",
      "digits using image proﬁles of multiple orientations,’’ Pattern Recognit.\n",
      "Lett., vol. 25, no. 14, pp. 1569–1576, Oct. 2004.\n",
      "\n",
      "[142] A. Broumandnia and J. Shanbehzadeh, ‘‘Fast Zernike wavelet moments\n",
      "for farsi character recognition,’’ Image Vis. Comput., vol. 25, no. 5,\n",
      "pp. 717–726, May 2007.\n",
      "\n",
      "[143] H. Freeman and L. Davis, ‘‘A corner-ﬁnding algorithm for chain-coded\n",
      "curves,’’ IEEE Trans. Comput., vol. C-26, no. 3, pp. 297–303, Mar. 1977.\n",
      "[144] G. Sokar, E. E. Hemayed, and M. Rehan, ‘‘A generic OCR using\n",
      "deep siamese convolution neural networks,’’ in Proc. IEEE 9th Annu.\n",
      "Inf. Technol., Electron. Mobile Commun. Conf. (IEMCON), Nov. 2018,\n",
      "pp. 1238–1244.\n",
      "\n",
      "[145] B. Alizadehashraf and S. Roohi, ‘‘Persian handwritten character recog-\n",
      "nition using convolutional neural network,’’ in Proc. 10th Iranian Conf.\n",
      "Mach. Vis. Image Process. (MVIP), Nov. 2017, pp. 247–251.\n",
      "\n",
      "[146] S. A. A. A. Arani, E. Kabir, and R. Ebrahimpour, ‘‘Handwritten farsi word\n",
      "recognition using NN-based fusion of HMM classiﬁers with different\n",
      "types of features,’’ Int. J. Image Graph., vol. 19, no. 01, Jan. 2019,\n",
      "Art. no. 1950001.\n",
      "\n",
      "[147] S. Naz, K. Hayat, M. I. Razzak, M. W. Anwar, S. A. Madani, and\n",
      "S. U. Khan, ‘‘The optical character recognition of Urdu-like cursive\n",
      "scripts,’’ Pattern Recognit., vol. 47, no. 3, pp. 1229–1248, Mar. 2014.\n",
      "\n",
      "J. Memon et al.: Handwritten OCR: A Comprehensive SLR\n",
      "\n",
      "[148] S. T. Javed and S. Hussain, ‘‘Improving nastalique speciﬁc pre-\n",
      "recognition process for Urdu OCR,’’ in Proc. IEEE 13th Int. Multitopic\n",
      "Conf., Dec. 2009, pp. 1–6.\n",
      "\n",
      "[149] M. W. Sagheer, C. L. He, N. Nobile, and C. Y. Suen, ‘‘A new large Urdu\n",
      "database for off-line handwriting recognition,’’ in Proc. Int. Conf. Image\n",
      "Anal. Process. Berlin, Germany: Springer, 2009, pp. 538–546.\n",
      "\n",
      "[150] A. Raza, I. Siddiqi, A. Abidi, and F. Arif, ‘‘An unconstrained bench-\n",
      "mark Urdu handwritten sentence database with automatic line segmen-\n",
      "tation,’’ in Proc. Int. Conf. Frontiers Handwriting Recognit., Sep. 2012,\n",
      "pp. 491–496.\n",
      "\n",
      "[151] S. M. Obaidullah, C. Halder, N. Das, and K. Roy, ‘‘Numeral script\n",
      "identiﬁcation from handwritten document images,’’ Procedia Comput.\n",
      "Sci., vol. 54, pp. 585–594, Jan. 2015.\n",
      "\n",
      "[152] I. Daubechies, Ten Lectures on Wavelets. Philadelphia, PA, USA: SIAM,\n",
      "\n",
      "1992.\n",
      "\n",
      "[153] A. Naseer and K. Zafar, ‘‘Comparative analysis of raw images and meta\n",
      "feature based Urdu OCR using CNN and LSTM,’’ Int. J. Adv. Comput.\n",
      "Sci. Appl., vol. 9, no. 1, pp. 419–424, 2018.\n",
      "\n",
      "[154] Sami-Ur-Rehman, B. U. Tayyab, M. F. Naeem, A. Ul-Hasan, and\n",
      "F. Shafait, ‘‘A multi-faceted OCR framework for artiﬁcial Urdu news\n",
      "ticker text recognition,’’ in Proc. 13th IAPR Int. Workshop Document\n",
      "Anal. Syst. (DAS), Apr. 2018, pp. 211–216.\n",
      "\n",
      "[155] S. B. Ahmed, S. Naz, S. Swati, and M. I. Razzak, ‘‘Handwritten Urdu\n",
      "character recognition using one-dimensional BLSTM classiﬁer,’’ Neural\n",
      "Comput. Appl., vol. 31, no. 4, pp. 1143–1151, Apr. 2019.\n",
      "\n",
      "[156] M. J. Rafeeq, Z. U. Rehman, A. Khan, I. A. Khan, and W. Jadoon, ‘‘Lig-\n",
      "ature categorization based nastaliq Urdu recognition using deep neural\n",
      "networks,’’ Comput. Math. Org. Theory, vol. 25, no. 2, pp. 184–195,\n",
      "Jun. 2019.\n",
      "\n",
      "[157] H.-T. Pao, Y. Y. Xu, H.-Y. Chang, and H.-C. Fu, ‘‘User adaptive hand-\n",
      "writing recognition by self-growing probabilistic decision-based neural\n",
      "networks,’’ IEEE Trans. Neural Netw., vol. 11, no. 6, pp. 1373–1384,\n",
      "Nov. 2000.\n",
      "\n",
      "[158] D. Lin, F. Lin, Y. Lv, F. Cai, and D. Cao, ‘‘Chinese character CAPTCHA\n",
      "recognition and performance estimation via deep neural network,’’ Neu-\n",
      "rocomputing, vol. 288, pp. 11–19, May 2018.\n",
      "\n",
      "[159] Y. Zhao, W. Xue, and Q. Li, ‘‘A multi-scale CRNN model for Chinese\n",
      "papery medical document recognition,’’ in Proc. IEEE 4th Int. Conf.\n",
      "Multimedia Big Data (BigMM), Sep. 2018, pp. 1–5.\n",
      "\n",
      "[160] Y. Luo, Y. Li, S. Huang, and F. Han, ‘‘Multiple Chinese vehicle license\n",
      "plate localization in complex scenes,’’ in Proc. IEEE 3rd Int. Conf. Image,\n",
      "Vis. Comput. (ICIVC), Jun. 2018, pp. 745–749.\n",
      "\n",
      "[161] H. Yang, L. Jin, and J. Sun, ‘‘Recognition of Chinese text in historical\n",
      "documents with page-level annotations,’’ in Proc. 16th Int. Conf. Fron-\n",
      "tiers Handwriting Recognit. (ICFHR), Aug. 2018, pp. 199–204.\n",
      "[162] H. Ren, W. Wang, and C. Liu, ‘‘Recognizing online handwritten Chinese\n",
      "characters using RNNs with new computing architectures,’’ Pattern\n",
      "Recognit., vol. 93, pp. 179–192, Sep. 2019.\n",
      "\n",
      "[163] X. Zhang and K. Yan, ‘‘An algorithm of bidirectional RNN for ofﬂine\n",
      "handwritten Chinese text recognition,’’ in Proc. Int. Conf. Intell. Comput.\n",
      "Cham, Switzerland: Springer, 2019, pp. 423–431.\n",
      "\n",
      "[164] Y. Zhu, F. Zhuang, J. Yang, X. Yang, and Q. He, ‘‘Adaptively trans-\n",
      "fer category-classiﬁer for handwritten Chinese character recognition,’’\n",
      "in Proc. Paciﬁc-Asia Conf. Knowl. Discovery Data Mining. Cham,\n",
      "Switzerland: Springer, 2019, pp. 110–122.\n",
      "[165] N. Mezghani, A. Mitiche, and M. Cheriet,\n",
      "\n",
      "‘‘On-line recognition\n",
      "of handwritten Arabic characters using a kohonen neural network,’’\n",
      "in Proc. 8th Int. Workshop Frontiers Handwriting Recognit., 2002,\n",
      "pp. 490–495.\n",
      "\n",
      "[166] S. Mozaffari, K. Faez, F. Faradji, M. Ziaratban, and S. M. Golzan,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‘‘A comprehensive isolated Farsi/Arabic character database for handwrit-\n",
      "ten OCR research,’’ in Proc. 10th Int. Workshop Frontiers Handwriting\n",
      "Recognit., 2006, pp. 1–6.\n",
      "\n",
      "[167] S. Mozaffari and H. Soltanizadeh,\n",
      "\n",
      "‘‘ICDAR 2009 handwritten\n",
      "Farsi/Arabic character recognition competition,’’ in Proc. 10th Int.\n",
      "Conf. Document Anal. Recognit. (ICDAR), 2009, pp. 1413–1417.\n",
      "[168] A. Mezghani, S. Kanoun, M. Khemakhem, and H. E. Abed, ‘‘A database\n",
      "for Arabic handwritten text image recognition and writer identiﬁca-\n",
      "tion,’’ in Proc. Int. Conf. Frontiers Handwriting Recognit., Sep. 2012,\n",
      "pp. 399–402.\n",
      "\n",
      "[169] M. Khayyat, L. Lam, and C. Y. Suen, ‘‘Learning-based word spotting\n",
      "system for Arabic handwritten documents,’’ Pattern Recognit., vol. 47,\n",
      "no. 3, pp. 1021–1030, Mar. 2014.\n",
      "\n",
      "142666\n",
      "\n",
      "VOLUME 8, 2020\n",
      "\n",
      "\n",
      "J. Memon et al.: Handwritten OCR: A Comprehensive SLR\n",
      "\n",
      "[170] M. Lutf, X. You, Y.-M. Cheung, and C. L. P. Chen, ‘‘Arabic font recog-\n",
      "nition based on diacritics features,’’ Pattern Recognit., vol. 47, no. 2,\n",
      "pp. 672–684, Feb. 2014.\n",
      "\n",
      "[171] Y. Elarian, I. Ahmad, S. Awaida, W. G. Al-Khatib, and A. Zidouri,\n",
      "‘‘An Arabic handwriting synthesis system,’’ Pattern Recognit., vol. 48,\n",
      "no. 3, pp. 849–861, Mar. 2015.\n",
      "\n",
      "[172] E. M. Hicham, H. Akram, and S. Khalid, ‘‘Using features of local den-\n",
      "sities, statistics and HMM toolkit (HTK) for ofﬂine Arabic handwriting\n",
      "text recognition,’’ J. Electr. Syst. Inf. Technol., vol. 4, no. 3, pp. 387–396,\n",
      "Dec. 2017.\n",
      "\n",
      "[173] M. Elleuch, R. Maalej, and M. Kherallah, ‘‘A new design based-SVM\n",
      "of the CNN classiﬁer architecture with dropout for ofﬂine Arabic hand-\n",
      "written recognition,’’ Procedia Comput. Sci., vol. 80, pp. 1712–1723,\n",
      "Jan. 2016.\n",
      "\n",
      "[174] C. Boufenar, A. Kerboua, and M. Batouche, ‘‘Investigation on deep\n",
      "learning for off-line handwritten Arabic character recognition,’’ Cognit.\n",
      "Syst. Res., vol. 50, pp. 180–195, Aug. 2018.\n",
      "\n",
      "[175] N. A. Jebril, H. R. Al-Zoubi, and Q. A. Al-Haija, ‘‘Recognition of hand-\n",
      "written Arabic characters using histograms of oriented gradient (HOG),’’\n",
      "Pattern Recognit. Image Anal., vol. 28, no. 2, pp. 321–345, Apr. 2018.\n",
      "\n",
      "[176] R. A. Khan, A. Meyer, H. Konik, and S. Bouakaz, ‘‘Pain detection through\n",
      "shape and appearance features,’’ in Proc. IEEE Int. Conf. Multimedia\n",
      "Expo (ICME), Jul. 2013, pp. 1–6.\n",
      "\n",
      "[177] A. T. Sahlol, M. A. Elaziz, M. A. A. Al-Qaness, and S. Kim, ‘‘Handwrit-\n",
      "ten Arabic optical character recognition approach based on hybrid whale\n",
      "optimization algorithm with neighborhood rough set,’’ IEEE Access,\n",
      "vol. 8, pp. 23011–23021, 2020.\n",
      "\n",
      "[178] K. Dutta, P. Krishnan, M. Mathew, and C. Jawahar, ‘‘Towards accurate\n",
      "handwritten word recognition for Hindi and Bangla,’’ in Proc. Nat.\n",
      "Conf. Comput. Vis., Pattern Recognit., Image Process., Graph. Singapore:\n",
      "Springer, 2019, pp. 367–372.\n",
      "\n",
      "[179] B. M. Sagar, G. Shobha, and R. P. Kumar, ‘‘OCR for printed Kannada\n",
      "text to machine editable format using database approach,’’ WSEAS Trans.\n",
      "Comput., vol. 7, no. 6, pp. 766–769, 2008.\n",
      "\n",
      "[180] G. Lehal and N. Bhatt, ‘‘A recognition system for Devnagri and English\n",
      "handwritten numerals,’’ in Advances in Multimodal Interfaces. Berlin,\n",
      "Germany: Springer, 2000, pp. 442–449.\n",
      "\n",
      "[181] F. Kimura and M. Shridhar, ‘‘Handwritten numerical recognition based\n",
      "on multiple algorithms,’’ Pattern Recognit., vol. 24, no. 10, pp. 969–983,\n",
      "Jan. 1991.\n",
      "\n",
      "[182] S. B. Patil and N. V. Subbareddy, ‘‘Neural network based system for script\n",
      "identiﬁcation in Indian documents,’’ Sadhana, vol. 27, no. 1, pp. 83–97,\n",
      "Feb. 2002.\n",
      "\n",
      "[183] M. Hanmandlu, J. Grover, V. K. Madasu, and S. Vasikarla, ‘‘Input fuzzy\n",
      "modeling for the recognition of handwritten Hindi numerals,’’ in Proc.\n",
      "4th Int. Conf. Inf. Technol. (ITNG), Apr. 2007, pp. 208–213.\n",
      "\n",
      "[184] N. K. Garg, D. L. Kaur, and D. M. Kumar, ‘‘Segmentation of handwritten\n",
      "\n",
      "hindi text,’’ Int. J. Comput. Appl., vol. 1, no. 4, pp. 22–26, Feb. 2010.\n",
      "\n",
      "[185] N. K. Garg, L. Kaur, and M. K. Jindal, ‘‘A new method for line segmenta-\n",
      "tion of handwritten hindi text,’’ in Proc. 7th Int. Conf. Inf. Technol., New\n",
      "Generat. (ITNG), 2010, pp. 392–397.\n",
      "\n",
      "[186] Y. Perwej and A. Chaturvedi, ‘‘Machine recognition of hand written\n",
      "characters using neural networks,’’ 2012, arXiv:1205.3964. [Online].\n",
      "Available: http://arxiv.org/abs/1205.3964\n",
      "\n",
      "[187] S. Karthik and K. S. Murthy, ‘‘Deep belief network based approach to\n",
      "recognize handwritten Kannada characters using distributed average of\n",
      "gradients,’’ Cluster Comput., vol. 22, no. S2, pp. 4673–4681, Mar. 2019.\n",
      "[188] S. Kowsalya and P. Periasamy, ‘‘Recognition of tamil handwritten charac-\n",
      "ter using modiﬁed neural network with aid of elephant herding optimiza-\n",
      "tion,’’ Multimedia Tools Appl., vol. 78, no. 17, pp. 25043–25061, 2019.\n",
      "\n",
      "[189] S. Naz, A. I. Umar, R. Ahmad, I. Siddiqi, S. B. Ahmed, M. I. Razzak,\n",
      "and F. Shafait, ‘‘Urdu nastaliq recognition using convolutional–recursive\n",
      "deep learning,’’ Neurocomputing, vol. 243, pp. 80–87, Jun. 2017.\n",
      "[190] M. Al-Ayyoub, A. Nuseir, K. Alsmearat, Y. Jararweh, and B. Gupta,\n",
      "‘‘Deep learning for Arabic NLP: A survey,’’ J. Comput. Sci., vol. 26,\n",
      "pp. 522–531, May 2018.\n",
      "\n",
      "[191] M. Kumar, M. K. Jindal, R. K. Sharma, and S. R. Jindal, ‘‘Ofﬂine\n",
      "handwritten numeral recognition using combination of different feature\n",
      "extraction techniques,’’ Nat. Acad. Sci. Lett., vol. 41, no. 1, pp. 29–33,\n",
      "Feb. 2018.\n",
      "\n",
      "[192] N. D. Cilia, C. D. Stefano, F. Fontanella, and A. S. di Freca,\n",
      "‘‘A ranking-based feature selection approach for handwritten character\n",
      "recognition,’’ Pattern Recognit. Lett., vol. 121, pp. 77–86, Apr. 2019.\n",
      "[Online]. Available: http://graphonomicsfor e-citizens: e-health, e-\n",
      "society, e-education and http://www.sciencedirect.com/science/article/\n",
      "pii/S0167865518301272\n",
      "\n",
      "[193] Y.-C. Wu, F. Yin, and C.-L. Liu, ‘‘Improving handwritten Chinese text\n",
      "recognition using neural network language models and convolutional\n",
      "neural network shape models,’’ Pattern Recognit., vol. 65, pp. 251–264,\n",
      "May 2017.\n",
      "\n",
      "[194] C. Shi, Y. Wang, F. Jia, K. He, C. Wang, and B. Xiao, ‘‘Fisher vector\n",
      "for scene character recognition: A comprehensive evaluation,’’ Pattern\n",
      "Recognit., vol. 72, pp. 1–14, Dec. 2017.\n",
      "\n",
      "[195] Z. Feng, Z. Yang, L. Jin, S. Huang, and J. Sun, ‘‘Robust shared feature\n",
      "learning for script and handwritten/machine-printed identiﬁcation,’’ Pat-\n",
      "tern Recognit. Lett., vol. 100, pp. 6–13, Dec. 2017.\n",
      "\n",
      "[196] X. Feng, H. Yao, and S. Zhang, ‘‘Focal CTC loss for Chinese optical\n",
      "character recognition on unbalanced datasets,’’ Complexity, vol. 2019,\n",
      "Jan. 2019, Art. no. 9345861.\n",
      "\n",
      "[197] L. Xu, Y. Wang, X. Li, and M. Pan, ‘‘Recognition of handwritten\n",
      "Chinese characters based on concept learning,’’ IEEE Access, vol. 7,\n",
      "pp. 102039–102053, 2019.\n",
      "\n",
      "[198] B. B. Chaudhuri and C. Adak, ‘‘An approach for detecting and cleaning\n",
      "of struck-out handwritten text,’’ Pattern Recognit., vol. 61, pp. 282–294,\n",
      "Jan. 2017.\n",
      "\n",
      "[199] B. Su and S. Lu, ‘‘Accurate recognition of words in scenes without char-\n",
      "acter segmentation using recurrent neural network,’’ Pattern Recognit.,\n",
      "vol. 63, pp. 397–405, Mar. 2017.\n",
      "\n",
      "[200] R. Graef and M. M. N. Morsy, ‘‘A novel hybrid optical character recogni-\n",
      "tion approach for digitizing text in forms,’’ in Proc. Int. Conf. Design Sci.\n",
      "Res. Inf. Syst. Technol. Cham, Switzerland: Springer, 2019, pp. 206–220.\n",
      "[201] M. Ahmed and A. I. Abidi, ‘‘Performance comparison of ANN and\n",
      "template matching on English character recognition,’’ Int. J. Advance\n",
      "Res., Ideas Innov. Technol., vol. 5, no. 4, pp. 367–372, 2019.\n",
      "\n",
      "[202] M. Yashodha, S. Niranjan, and V. N. M. Aradhya, ‘‘Deep learning for\n",
      "trilingual character recognition,’’ Int. J. Natural Comput. Res., vol. 8,\n",
      "no. 1, pp. 52–58, Jan. 2019.\n",
      "\n",
      "[203] A. Yousaf, M. J. Khan, M. J. Khan, N. Javed, H. Ibrahim, K. Khurshid,\n",
      "and K. Khurshid, ‘‘Size invariant handwritten character recognition using\n",
      "single layer feedforward backpropagation neural networks,’’ in Proc. 2nd\n",
      "Int. Conf. Comput., Math. Eng. Technol. (iCoMET), Jan. 2019, pp. 1–7.\n",
      "\n",
      "[204] S. Yousﬁ, S.-A. Berrani, and C. Garcia, ‘‘Contribution of recur-\n",
      "rent connectionist language models in improving LSTM-based Arabic\n",
      "text recognition in videos,’’ Pattern Recognit., vol. 64, pp. 245–254,\n",
      "Apr. 2017.\n",
      "\n",
      "[205] R. Elanwar, W. Qin, and M. Betke, ‘‘Making scanned Arabic documents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "machine accessible using an ensemble of SVM classiﬁers,’’ Int. J. Docu-\n",
      "ment Anal. Recognit., vol. 21, nos. 1–2, pp. 59–75, Jun. 2018.\n",
      "\n",
      "[206] I. A. Doush, F. Alkhateeb, and A. H. Gharaibeh, ‘‘A novel Arabic OCR\n",
      "post-processing using rule-based and word context techniques,’’ Int. J.\n",
      "Document Anal. Recognit., vol. 21, nos. 1–2, pp. 77–89, 2018.\n",
      "\n",
      "[207] S. S. R. Rizvi, A. Sagheer, K. Adnan, and A. Muhammad, ‘‘Optical\n",
      "character recognition system for nastalique Urdu-like script languages\n",
      "using supervised learning,’’ Int. J. Pattern Recognit. Artif. Intell., vol. 33,\n",
      "no. 10, Sep. 2019, Art. no. 1953004.\n",
      "\n",
      "[208] K. U. U. Rehman and Y. D. Khan, ‘‘A scale and rotation invariant Urdu\n",
      "Nastalique ligature recognition using cascade forward back propagation\n",
      "neural network,’’ IEEE Access, vol. 7, pp. 120648–120669, 2019.\n",
      "[209] R. Sarkhel, N. Das, A. Das, M. Kundu, and M. Nasipuri, ‘‘A multi-scale\n",
      "deep quad tree based feature extraction method for the recognition of iso-\n",
      "lated handwritten characters of popular indic scripts,’’ Pattern Recognit.,\n",
      "vol. 71, pp. 78–93, Nov. 2017.\n",
      "\n",
      "[210] F. Sarvaramini, A. Nasrollahzadeh, and M. Soryani, ‘‘Persian handwrit-\n",
      "ten character recognition using convolutional neural network,’’ in Proc.\n",
      "Iranian Conf. Electr. Eng. (ICEE), 2018, pp. 1676–1680.\n",
      "\n",
      "[211] S. Valikhani, F. Abdali-Mohammadi, and A. Fathi, ‘‘Online continu-\n",
      "ous multi-stroke Persian/Arabic character recognition by novel spatio-\n",
      "temporal features for digitizer pen devices,’’ Neural Comput. Appl.,\n",
      "vol. 32, pp. 3853–3872, May 2019.\n",
      "\n",
      "[212] P. Kiaei, M. Javaheripi, and H. Mohammadzade, ‘‘High accuracy farsi\n",
      "language character segmentation and recognition,’’ in Proc. 27th Iranian\n",
      "Conf. Electr. Eng. (ICEE), Apr. 2019, pp. 1692–1698.\n",
      "\n",
      "[213] S. Long, X. He, and C. Yao, ‘‘Scene text detection and recognition:\n",
      "The deep learning era,’’ 2018, arXiv:1811.04256. [Online]. Available:\n",
      "https://arxiv.org/abs/1811.04256\n",
      "\n",
      "[214] O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang,\n",
      "A. Karpathy, A. Khosla, M. Bernstein, A. C. Berg, and L. Fei-Fei,\n",
      "‘‘ImageNet large scale visual recognition challenge,’’ Int. J. Comput. Vis.,\n",
      "vol. 115, no. 3, pp. 211–252, Dec. 2015.\n",
      "\n",
      "VOLUME 8, 2020\n",
      "\n",
      "142667\n",
      "\n",
      "\n",
      "[215] A. Krizhevsky, I. Sutskever, and G. E. Hinton, ‘‘ImageNet classiﬁ-\n",
      "cation with deep convolutional neural networks,’’ in Proc. 25th Int.\n",
      "Conf. Neural Inf. Process. Syst. (NIPS), vol. 1. Red Hook, NY,\n",
      "USA: Curran Associates, 2012, pp. 1097–1105. [Online]. Available:\n",
      "http://dl.acm.org/citation.cfm?id=2999134.2999257\n",
      "\n",
      "[216] C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan,\n",
      "V. Vanhoucke, and A. Rabinovich, ‘‘Going deeper with convolutions,’’\n",
      "in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), Jun. 2015,\n",
      "pp. 1–9.\n",
      "\n",
      "[217] K. He, X. Zhang, S. Ren, and J. Sun, ‘‘Deep residual learning for\n",
      "image recognition,’’ in Proc. IEEE Conf. Comput. Vis. Pattern Recognit.\n",
      "(CVPR), Jun. 2016, pp. 770–778.\n",
      "\n",
      "[218] T.-L. Yuan, Z. Zhu, K. Xu, C.-J. Li, T.-J. Mu, and S.-M. Hu, ‘‘A large\n",
      "Chinese text dataset in the wild,’’ J. Comput. Sci. Technol., vol. 34, no. 3,\n",
      "pp. 509–521, May 2019, doi: 10.1007/s11390-019-1923-y.\n",
      "\n",
      "[219] N. Nayef, Y. Patel, M. Busta, P. N. Chowdhury, D. Karatzas,\n",
      "W. Khlif, J. Matas, U. Pal, J.-C. Burie, C.-L. Liu, and J.-M. Ogier,\n",
      "‘‘ICDAR2019 robust reading challenge on multi-lingual scene text\n",
      "detection and recognition—RRC-MLT-2019,’’ 2019, arXiv:1907.00945.\n",
      "[Online]. Available: https://arxiv.org/abs/1907.00945\n",
      "\n",
      "[220] G. D. Markman, D. S. Siegel, and M. Wright, ‘‘Research and technology\n",
      "commercialization,’’ J. Manage. Stud., vol. 45, no. 8, pp. 1401–1423,\n",
      "2008. [Online]. Available: https://onlinelibrary.wiley.com/ doi/abs/10.\n",
      "1111/j.1467-6486.2008.00803.x\n",
      "\n",
      "J. Memon et al.: Handwritten OCR: A Comprehensive SLR\n",
      "\n",
      "MAIRA SAMI received the B.E. degree in the ﬁeld\n",
      "of computer and information systems engineering,\n",
      "and the master’s degree in data engineering and\n",
      "information management from the NED Univer-\n",
      "sity of Engineering and Technology (NEDUET).\n",
      "She is currently working as a Faculty Member with\n",
      "SZABIST, Karachi, Pakistan.\n",
      "\n",
      "RIZWAN AHMED KHAN received the Ph.D.\n",
      "degree in computer science from Université\n",
      "Claude Bernard Lyon 1, France, in 2013. He has\n",
      "worked as a Postdoctoral Research Associate\n",
      "with the Laboratoire d’InfoRmatique en Image et\n",
      "Systemes d’information (LIRIS), Lyon, France.\n",
      "He is currently working as a Professor with\n",
      "Barrett Hodgson University, Karachi, Pakistan.\n",
      "His research interests include artiﬁcial\n",
      "intelli-\n",
      "gence, computer vision, machine learning, and\n",
      "human perception.\n",
      "\n",
      "JAMSHED MEMON received the Ph.D. degree\n",
      "in information systems from Universiti Teknologi\n",
      "Malaysia, in 2015. He is currently working as\n",
      "an Associate Professor with Quest International\n",
      "University Perak (QIUP), Malaysia. He has exten-\n",
      "sive research and industry experience. He has\n",
      "authored over 20 international research articles.\n",
      "His research interests include green information\n",
      "technology, information security, and technology\n",
      "entrepreneurship.\n",
      "\n",
      "MUEEN UDDIN received the Bachelor of Sci-\n",
      "ence and Master of Science degrees in computer\n",
      "sciences from Isra University, Pakistan, and the\n",
      "Ph.D. degree from Universiti Teknologi Malaysia\n",
      "(UTM). He is currently working as an Associate\n",
      "Professor with Ilma University, Karachi, Pakistan.\n",
      "He possesses diverse education and research back-\n",
      "ground. He also possesses very strong research and\n",
      "publication background with over 85 international\n",
      "publications to his name. He has strong networks\n",
      "and security related background, where he has developed many algorithms\n",
      "and techniques to secure networks and cloud related applications. He is also\n",
      "working on blockchain technology to provide and enable healthcare related\n",
      "solutions.\n",
      "\n",
      "142668\n",
      "\n",
      "VOLUME 8, 2020\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#結果を改行して出力\n",
    "for text in result.splitlines():\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ページ指定して出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_numbers=[0]\n",
    "result = extract_text(pdf, page_numbers=page_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received June 24, 2020, accepted July 16, 2020, date of publication July 28, 2020, date of current version August 14, 2020.\n",
      "\n",
      "Digital Object Identifier 10.1109/ACCESS.2020.3012542\n",
      "\n",
      "Handwritten Optical Character Recognition\n",
      "(OCR): A Comprehensive Systematic\n",
      "Literature Review (SLR)\n",
      "\n",
      "JAMSHED MEMON 1, MAIRA SAMI 2, RIZWAN AHMED KHAN 3, AND MUEEN UDDIN 4\n",
      "1School of Computing, Quest International University Perak, Ipoh 30250, Malaysia\n",
      "2Department of Computer Science, Shaheed Zulﬁqar Ali Bhutto Institute of Science and Technology, Karachi 75600, Pakistan\n",
      "3Faculty of IT, Barrett Hodgson University, Karachi 74900, Pakistan\n",
      "4Department of Software Engineering, Faculty of Science and Technology, Ilma University, Karachi 75190, Pakistan\n",
      "\n",
      "Corresponding author: Maira Sami (maira.sami@szabist.edu.pk)\n",
      "\n",
      "ABSTRACT Given the ubiquity of handwritten documents in human transactions, Optical Character\n",
      "Recognition (OCR) of documents have invaluable practical worth. Optical character recognition is a science\n",
      "that enables to translate various types of documents or images into analyzable, editable and searchable data.\n",
      "During last decade, researchers have used artiﬁcial intelligence / machine learning tools to automatically\n",
      "analyze handwritten and printed documents in order to convert them into electronic format. The objective of\n",
      "this review paper is to summarize research that has been conducted on character recognition of handwritten\n",
      "documents and to provide research directions. In this Systematic Literature Review (SLR) we collected,\n",
      "synthesized and analyzed research articles on the topic of handwritten OCR (and closely related topics)\n",
      "which were published between year 2000 to 2019. We followed widely used electronic databases by\n",
      "following pre-deﬁned review protocol. Articles were searched using keywords, forward reference searching\n",
      "and backward reference searching in order to search all the articles related to the topic. After carefully\n",
      "following study selection process 176 articles were selected for this SLR. This review article serves the\n",
      "purpose of presenting state of the art results and techniques on OCR and also provide research directions by\n",
      "highlighting research gaps.\n",
      "\n",
      "INDEX TERMS Optical character recognition, classiﬁcation, languages, feature extraction, deep learning.\n",
      "\n",
      "I. INTRODUCTION\n",
      "PTICAL character recognition (OCR) is a system that con-\n",
      "verts input text into machine-encoded format [1]. Today, OCR\n",
      "is helping not only in digitizing the handwritten medieval\n",
      "manuscripts [2], but also helps in converting the typewritten\n",
      "documents into digital form [3]. This has made the retrieval\n",
      "of the required information easier as one doesn’t have to\n",
      "go through the piles of documents and ﬁles to search the\n",
      "required information. Organizations are satisfying the needs\n",
      "of digital preservation of historic data [4], law documents [5],\n",
      "educational persistence [6] etc.\n",
      "\n",
      "An OCR system depends mainly, on the extraction of\n",
      "features and discrimination/classiﬁcation of these features\n",
      "(based on patterns). Handwritten OCR have received increas-\n",
      "ing attention as a subﬁeld of OCR. It is further categorized\n",
      "into ofﬂine system [7], [8] and online system [9] based on\n",
      "\n",
      "The associate editor coordinating the review of this manuscript and\n",
      "\n",
      "approving it for publication was Jenny Mahoney.\n",
      "\n",
      "input data. The ofﬂine system is a static system in which\n",
      "input data is in the form of scanned images while in online\n",
      "systems nature of input is more dynamic and is based on\n",
      "the movement of pen tip having certain velocity, projection\n",
      "angle, position and locus point. Therefore, an online system\n",
      "is considered more complex and advance, as it resolves the\n",
      "overlapping problem of input data that is present in the ofﬂine\n",
      "system.\n",
      "\n",
      "One of the earliest OCR systems was developed in the\n",
      "1940s, with the advancement in the technology over the time,\n",
      "the system became more robust to deal with both printed,\n",
      "and handwritten characters and this led to the commercial\n",
      "availability of the OCR machines. In 1965, advance reading\n",
      "machine ‘‘IBM 1287’’ was introduced at the ‘‘world fair’’ in\n",
      "New York [10]. This was the ﬁrst-ever optical reader, which\n",
      "was capable of reading handwritten numbers. During the\n",
      "1970s, researchers focused on the improvement of response\n",
      "time and performance of the OCR system.\n",
      "\n",
      "142642\n",
      "\n",
      "This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\n",
      "\n",
      "VOLUME 8, 2020\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#結果を改行して出力\n",
    "for text in result.splitlines():\n",
    "    print(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
